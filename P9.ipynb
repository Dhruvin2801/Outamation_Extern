{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39943,"status":"ok","timestamp":1758526179236,"user":{"displayName":"Dfe Shah","userId":"02290639415740118939"},"user_tz":-330},"id":"t7LSK5SUQoHO","outputId":"0ec08613-4377-46cd-ded4-e9547efb4d56"},"outputs":[{"name":"stdout","output_type":"stream","text":["⏳ Installing all dependencies... This may take several minutes.\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.8/30.8 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h✅ Installations complete.\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/pypdf/_crypt_providers/_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from this module in 48.0.0.\n","  from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4\n","[nltk_data] Downloading package punkt_tab to\n","[nltk_data]     /usr/local/lib/python3.12/dist-\n","[nltk_data]     packages/llama_index/core/_static/nltk_cache...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n"]},{"name":"stdout","output_type":"stream","text":["⏳ Loading LLM and Embedding Model...\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["✅ Models loaded successfully.\n"]}],"source":["# ==============================================================================\n","# Part 1: Installations\n","# ==============================================================================\n","print(\"⏳ Installing all dependencies... This may take several minutes.\")\n","!pip install --upgrade gradio gradio_client websockets -q\n","!pip install llama-index==0.10.34 pypdf==4.2.0 pymupdf==1.24.1 -q\n","!pip install llama-cpp-python==0.2.73 --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu122 -q\n","!pip install llama-index-llms-llama-cpp==0.1.3 llama-index-embeddings-huggingface==0.2.0 -q\n","print(\"✅ Installations complete.\")\n","\n","\n","# ==============================================================================\n","# Part 2: Setup and Model Loading\n","# ==============================================================================\n","import gradio as gr\n","import os\n","import json\n","import time\n","import fitz  # PyMuPDF\n","from pypdf import PdfReader\n","from llama_index.core import Document, VectorStoreIndex, Settings\n","from llama_index.core.vector_stores import ExactMatchFilter, MetadataFilters\n","from llama_index.llms.llama_cpp import LlamaCPP\n","from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n","from typing import List, Dict\n","from PIL import Image\n","\n","# Download and load the open-source models\n","model_path = \"/content/mistral-7b-instruct-v0.2.Q4_K_M.gguf\"\n","if not os.path.exists(model_path):\n","    print(\"⏳ Downloading Mistral 7B model... (approx. 4.1 GB)\")\n","    !wget https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q4_K_M.gguf -O {model_path}\n","\n","print(\"⏳ Loading LLM and Embedding Model...\")\n","Settings.llm = LlamaCPP(\n","    model_path=model_path, temperature=0.1, max_new_tokens=512,\n","    context_window=3900, model_kwargs={\"n_gpu_layers\": 35}, verbose=False\n",")\n","Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n","print(\"✅ Models loaded successfully.\")\n","\n","\n","# ==============================================================================\n","# Part 3: Backend Pipeline Logic\n","# ==============================================================================\n","class DocumentIntelligencePipeline:\n","    def __init__(self):\n","        self.index = None; self.file_name = \"\"\n","        self.doc_types_in_file = []; self.known_doc_types = [\"Lender Fee Sheet\", \"Payslip\", \"Contract\", \"Other\"]\n","\n","    def segment_and_index_document(self, pdf_path: str):\n","        start_time = time.time()\n","        self.file_name = os.path.basename(pdf_path)\n","        reader = PdfReader(pdf_path)\n","        pages = [{\"text\": page.extract_text()} for page in reader.pages]\n","        if not pages: raise ValueError(\"Could not extract pages.\")\n","\n","        documents_to_index = []\n","        doc_types_found = set()\n","        for i, page in enumerate(pages):\n","            doc_type = \"Document\" # Simplified segmentation for robustness\n","            doc_types_found.add(doc_type)\n","            metadata = {\"page_number\": i + 1, \"doc_type\": doc_type, \"file_name\": self.file_name}\n","            doc = Document(text=page['text'], metadata=metadata)\n","            documents_to_index.append(doc)\n","\n","        self.index = VectorStoreIndex.from_documents(documents_to_index)\n","\n","        processing_time = time.time() - start_time\n","        self.doc_types_in_file = list(doc_types_found)\n","        stats = {\n","            \"File\": self.file_name, \"Pages\": len(pages), \"Chunks\": len(documents_to_index),\n","            \"Types\": \", \".join(self.doc_types_in_file), \"Time\": f\"{processing_time:.2f}s\"\n","        }\n","        return stats\n","\n","    def query(self, user_query: str, filter_type: str, auto_route: bool, top_k: int):\n","        if not self.index: return {\"answer\": \"Please process a document first.\", \"sources\": \"\"}\n","        retriever_args = {\"similarity_top_k\": int(top_k)}\n","        doc_type_to_search = filter_type\n","        if auto_route and filter_type == \"All\":\n","            prompt = f\"[INST] You are a query router. Classify the user's query into one of these categories: {self.doc_types_in_file}. Query: '{user_query}' [/INST]\"\n","            predicted = Settings.llm.complete(prompt).text.strip()\n","            print(f\"🎯 Auto-routing to: {predicted}\")\n","            if predicted in self.doc_types_in_file: doc_type_to_search = predicted\n","        if doc_type_to_search != \"All\":\n","             retriever_args[\"filters\"] = MetadataFilters(filters=[ExactMatchFilter(key=\"doc_type\", value=doc_type_to_search)])\n","\n","        retriever = self.index.as_retriever(**retriever_args)\n","        nodes = retriever.retrieve(user_query)\n","        context = \"\\n\\n\".join([n.get_text() for n in nodes])\n","        prompt = f\"[INST] Use context to answer. If unsure, say so.\\nContext:\\n{context}\\n\\nQuestion: {user_query} [/INST]\"\n","        response = Settings.llm.complete(prompt)\n","        sources = \"--- SOURCES ---\\n\" + \"\\n\".join([f\"**Source {i+1} (Page: {n.metadata['page_number']})**:\\n```{n.get_text().strip()}```\" for i, n in enumerate(nodes)])"]},{"cell_type":"markdown","metadata":{"id":"U5T--kNQ0rjl"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":773},"executionInfo":{"elapsed":95807,"status":"error","timestamp":1759124146099,"user":{"displayName":"Dfe Shah","userId":"02290639415740118939"},"user_tz":-330},"id":"DlPEIjb0Ubkl","outputId":"8555db22-0a7c-47d0-8ab4-d5540279c5be"},"outputs":[{"name":"stdout","output_type":"stream","text":["⏳ Installing all dependencies... This may take several minutes.\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.4/325.4 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.8/30.8 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","opencv-python-headless 4.12.0.88 requires numpy\u003c2.3.0,\u003e=2; python_version \u003e= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","thinc 8.3.6 requires numpy\u003c3.0.0,\u003e=2.0.0, but you have numpy 1.26.4 which is incompatible.\n","opencv-python 4.12.0.88 requires numpy\u003c2.3.0,\u003e=2; python_version \u003e= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","opencv-contrib-python 4.12.0.88 requires numpy\u003c2.3.0,\u003e=2; python_version \u003e= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.6/156.6 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h✅ Installations complete. Please go to 'Runtime \u003e Restart session' before proceeding to Step 2.\n"]},{"ename":"ValueError","evalue":"numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-230806205.py\u001b[0m in \u001b[0;36m\u003ccell line: 0\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Step 2: Setup and Model Loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# ==============================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 18\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgradio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gradio/__init__.py\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_templates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessing_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gradio/_simple_templates/__init__.py\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msimpledropdown\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSimpleDropdown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msimpleimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSimpleImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msimpletextbox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSimpleTextbox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"SimpleDropdown\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SimpleTextbox\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SimpleImage\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gradio/_simple_templates/simpledropdown.py\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mComponent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFormComponent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi18n\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mI18nData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gradio/components/__init__.py\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotated_image\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAnnotatedImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m from gradio.components.base import (\n\u001b[1;32m      4\u001b[0m     \u001b[0mComponent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mFormComponent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gradio/components/annotated_image.py\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprocessing_utils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mComponent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_classes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFileData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGradioModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gradio/components/base.py\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBlockContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponent_meta\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mComponentMeta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m from gradio.data_classes import (\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgroovy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtranspile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 34\u001b[0;31m from gradio import (\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0manalytics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mcomponents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gradio/queueing.py\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfastapi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 17\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0manyio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_thread\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrun_sync\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m     ) from _err\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 37\u001b[0;31m from pandas._config import (\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mget_option\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mset_option\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/_config/__init__.py\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;34m\"warn_copy_on_write\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m ]\n\u001b[0;32m---\u003e 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdates\u001b[0m  \u001b[0;31m# pyright: ignore[reportUnusedImport]  # noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m from pandas._config.config import (\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/_config/config.py\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 68\u001b[0;31m from pandas._typing import (\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/_typing.py\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 198\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBitGenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 337\u001b[0;31m         \u001b[0mpublic_symbols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'testing'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         public_symbols -= {\n\u001b[1;32m    339\u001b[0m             \u001b[0;34m\"core\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"matrixlib\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/random/__init__.py\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;31m# add these for module-freeze analysis (like PyInstaller)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 180\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_common\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_bounded_integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/random/_pickle.py\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmtrand\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_philox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPhilox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_pcg64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCG64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPCG64DXSM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_sfc64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSFC64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mnumpy/random/mtrand.pyx\u001b[0m in \u001b[0;36minit numpy.random.mtrand\u001b[0;34m()\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"]}],"source":["# ==============================================================================\n","# Step 1: Installations\n","# ==============================================================================\n","print(\"⏳ Installing all dependencies... This may take several minutes.\")\n","\n","# Install Gradio and the custom PDF component for the viewer\n","!pip install --upgrade gradio gradio_client websockets -q\n","!pip install gradio_pdf -q\n","\n","# Install libraries for the backend AI pipeline\n","!pip install llama-index==0.10.34 pypdf==4.2.0 pymupdf==1.24.1 -q\n","!pip install llama-cpp-python==0.2.73 --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu122 -q\n","!pip install llama-index-llms-llama-cpp==0.1.3 llama-index-embeddings-huggingface==0.2.0 -q\n","print(\"✅ Installations complete. Please go to 'Runtime \u003e Restart session' before proceeding to Step 2.\")\n","# ==============================================================================\n","# Step 2: Setup and Model Loading\n","# ==============================================================================\n","import gradio as gr\n","import os\n","import json\n","import time\n","import fitz  # PyMuPDF for PDF preview\n","from pypdf import PdfReader\n","from llama_index.core import Document, VectorStoreIndex, Settings\n","from llama_index.core.vector_stores import ExactMatchFilter, MetadataFilters\n","from llama_index.llms.llama_cpp import LlamaCPP\n","from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n","from typing import List, Dict\n","from PIL import Image\n","\n","# Download and load the open-source models\n","model_path = \"/content/mistral-7b-instruct-v0.2.Q4_K_M.gguf\"\n","if not os.path.exists(model_path):\n","    print(\"⏳ Downloading Mistral 7B model... (approx. 4.1 GB)\")\n","    !wget https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q4_K_M.gguf -O {model_path}\n","\n","print(\"⏳ Loading LLM and Embedding Model...\")\n","Settings.llm = LlamaCPP(\n","    model_path=model_path, temperature=0.1, max_new_tokens=512,\n","    context_window=3900, model_kwargs={\"n_gpu_layers\": 35}, verbose=False\n",")\n","Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n","print(\"✅ Models loaded successfully.\")\n","\n","# ==============================================================================\n","# Step 3: Define the Backend Pipeline Logic\n","# ==============================================================================\n","class DocumentIntelligencePipeline:\n","    def __init__(self):\n","        self.index = None; self.file_name = \"\"\n","        self.doc_types_in_file = []; self.known_doc_types = [\"Lender Fee Sheet\", \"Payslip\", \"Contract\", \"Other\"]\n","\n","    def process_and_index_document(self, pdf_path: str):\n","        start_time = time.time()\n","        self.file_name = os.path.basename(pdf_path)\n","        reader = PdfReader(pdf_path)\n","        pages = [{\"text\": page.extract_text()} for page in reader.pages]\n","        if not pages: raise ValueError(\"Could not extract pages from PDF.\")\n","\n","        documents_to_index = []\n","        doc_types_found = set()\n","        for i, page in enumerate(pages):\n","            # A more advanced pipeline would use an LLM to classify each doc type\n","            doc_type = \"Document\"\n","            doc_types_found.add(doc_type)\n","            metadata = {\"page_number\": i + 1, \"doc_type\": doc_type, \"file_name\": self.file_name}\n","            doc = Document(text=page['text'], metadata=metadata)\n","            documents_to_index.append(doc)\n","\n","        self.index = VectorStoreIndex.from_documents(documents_to_index)\n","\n","        processing_time = time.time() - start_time\n","        self.doc_types_in_file = list(doc_types_found)\n","        stats = {\n","            \"File\": self.file_name, \"Pages\": len(pages), \"Chunks\": len(documents_to_index),\n","            \"Types\": \", \".join(self.doc_types_in_file), \"Time\": f\"{processing_time:.2f}s\"\n","        }\n","        return stats\n","\n","    def query(self, user_query: str, filter_type: str, auto_route: bool, top_k: int):\n","        if not self.index: return {\"answer\": \"Please process a document first.\", \"sources\": \"\"}\n","\n","        retriever_args = {\"similarity_top_k\": int(top_k)}\n","        doc_type_to_search = filter_type\n","\n","        if auto_route and filter_type == \"All\":\n","            prompt = f\"[INST] You are a query router. Classify the user's query into one of these categories: {self.doc_types_in_file}. Query: '{user_query}' [/INST]\"\n","            predicted = Settings.llm.complete(prompt).text.strip()\n","            print(f\"🎯 Auto-routing to: {predicted}\")\n","            if predicted in self.doc_types_in_file: doc_type_to_search = predicted\n","\n","        if doc_type_to_search != \"All\":\n","             retriever_args[\"filters\"] = MetadataFilters(filters=[ExactMatchFilter(key=\"doc_type\", value=doc_type_to_search)])\n","\n","        retriever = self.index.as_retriever(**retriever_args)\n","        nodes = retriever.retrieve(user_query)\n","        context = \"\\n\\n\".join([n.get_text() for n in nodes])\n","        prompt = f\"[INST] Use the provided context to answer the question. If the answer is not in the context, say so.\\n\\nContext:\\n{context}\\n\\nQuestion: {user_query} [/INST]\"\n","        response = Settings.llm.complete(prompt)\n","        sources = \"--- SOURCES ---\\n\" + \"\\n\".join([f\"**Source {i+1} (Page: {n.metadata['page_number']})**:\\n```{n.get_text().strip()}```\" for i, n in enumerate(nodes)])\n","\n","# ==============================================================================\n","# Step 4: Build the Gradio UI and Event Handlers\n","# ==============================================================================\n","def process_pdf_and_update_ui(file, progress=gr.Progress()):\n","    if file is None:\n","        return None, \"⚠️ Please upload a PDF file.\", [], gr.update(interactive=False), gr.update(choices=[\"All\"], value=\"All\")\n","\n","    # Generate a preview of the first page\n","    try:\n","        doc = fitz.open(file.name)\n","        page = doc[0]\n","        pix = page.get_pixmap(dpi=150)\n","        preview_image = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n","        doc.close()\n","    except Exception as e:\n","        print(f\"Error generating preview: {e}\")\n","        preview_image = None\n","\n","    progress(0, desc=\"Starting...\")\n","    try:\n","        progress(0.1, desc=\"📄 Processing and indexing PDF...\")\n","        stats = pipeline.process_and_index_document(file.name)\n","        info_text = \"\\n\".join([f\"- **{key}:** {value}\" for key, value in stats.items()])\n","        info_text = f\"✅ **Successfully Processed:**\\n{info_text}\"\n","        progress(1.0, desc=\"✅ Ready.\")\n","        return preview_image, info_text, [], gr.update(interactive=True), gr.update(choices=[\"All\"] + pipeline.doc_types_in_file, value=\"All\")\n","    except Exception as e:\n","        return None, f\"❌ Error: {e}\", None, gr.update(interactive=False), gr.update(choices=[\"All\"], value=\"All\")\n","\n","def chat_handler(message, history, filter_type, auto_route, top_k):\n","    if not pipeline.index:\n","        history.append({\"role\": \"user\", \"content\": message})\n","        history.append({\"role\": \"assistant\", \"content\": \"Please process a document first.\"})\n","        yield history, \"\", \"\"\n","        return\n","\n","    history.append({\"role\": \"user\", \"content\": message})\n","    history.append({\"role\": \"assistant\", \"content\": \"Thinking...\"})\n","    yield history, \"\", \"\"\n","\n","    result = pipeline.query(message, filter_type, auto_route, top_k)\n","    history[-1]['content'] = result[\"answer\"]\n","    yield history, result[\"sources\"], \"\"\n","\n","with gr.Blocks(theme=gr.themes.Soft(primary_hue=\"sky\"), title=\"Enhanced Document Q\u0026A\") as app:\n","    gr.Markdown(\"# 🚀 Enhanced Document Q\u0026A System\")\n","    gr.Markdown(\"An end-to-end pipeline for intelligent document analysis using an open-source LLM.\")\n","\n","    with gr.Row(equal_height=False):\n","        # Column 1: File Uploader \u0026 Preview\n","        with gr.Column(scale=4, min_width=400):\n","            # Using gr.File for upload, and gr.Image for preview\n","            file_uploader = gr.File(label=\"📄 Upload PDF File\", file_types=[\".pdf\"])\n","            process_btn = gr.Button(\"⚙️ Process Document\", variant=\"primary\")\n","            pdf_preview = gr.Image(label=\"PDF Preview (First Page)\", height=650)\n","\n","        # Column 2: Info \u0026 Settings Panel\n","        with gr.Column(scale=2, min_width=300):\n","            gr.Markdown(\"### 📊 Document Info\")\n","            info_output = gr.Markdown(value=\"Please upload a PDF file to begin.\")\n","\n","            gr.Markdown(\"### ⚙️ Settings\")\n","            doc_filter = gr.Dropdown(choices=[\"All\"], value=\"All\", label=\"🏷️ Document Type Filter\")\n","            auto_route = gr.Checkbox(value=True, label=\"🎯 Auto-Route Queries\")\n","            chunks_to_retrieve = gr.Slider(minimum=1, maximum=10, value=3, step=1, label=\"📊 Chunks to Retrieve\")\n","\n","        # Column 3: Chat Panel\n","        with gr.Column(scale=4, min_width=400):\n","            gr.Markdown(\"### 💬 Ask Questions\")\n","            chatbot = gr.Chatbot(label=\"Chat\", height=500, type=\"messages\", avatar_images=(None, \"https://i.imgur.com/C7MMFf1.png\"))\n","            source_display = gr.Markdown(label=\"Sources Used for Answer\")\n","            msg_box = gr.Textbox(label=\"Your Question\", placeholder=\"Ask a question...\", interactive=False, container=False)\n","\n","    # Event Handlers\n","    process_btn.click(\n","        process_pdf_and_update_ui,\n","        inputs=[file_uploader],\n","        outputs=[pdf_preview, info_output, chatbot, msg_box, doc_filter]\n","    )\n","\n","    msg_box.submit(\n","        chat_handler,\n","        inputs=[msg_box, chatbot, doc_filter, auto_route, chunks_to_retrieve],\n","        outputs=[chatbot, source_display, msg_box]\n","    )\n","\n","### **Step 5: Launch the Application**\n","\n","# ==============================================================================\n","# Step 5: Launch the Application\n","# ==============================================================================\n","test_file_path = \"/content/Test Blob File.pdf\"\n","if not os.path.exists(test_file_path):\n","    print(\"⏳ Downloading test file 'Test Blob File.pdf'...\")\n","    !wget -q https://storage.googleapis.com/generativeai-downloads/data/Test%20Blob%20File.pdf -O \"/content/Test Blob File.pdf\"\n","print(\"\\n🚀 Launching Gradio App... Please upload the 'Test Blob File.pdf' in the UI to begin.\")\n","app.launch(debug=True, share=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kr7xBog-1OsN","outputId":"94cdb7bc-c323-4e78-bac5-9679e3653dbf"},"outputs":[{"name":"stdout","output_type":"stream","text":["⏳ Installing dependencies... This may take several minutes.\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","yfinance 0.2.65 requires websockets\u003e=13.0, but you have websockets 11.0.3 which is incompatible.\n","google-adk 1.13.0 requires websockets\u003c16.0.0,\u003e=15.0.1, but you have websockets 11.0.3 which is incompatible.\n","dataproc-spark-connect 0.8.3 requires websockets\u003e=14.0, but you have websockets 11.0.3 which is incompatible.\n","google-genai 1.34.0 requires websockets\u003c15.1.0,\u003e=13.0.0, but you have websockets 11.0.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mTraceback (most recent call last):\n","  File \"/usr/local/bin/pip3\", line 4, in \u003cmodule\u003e\n","    from pip._internal.cli.main import main\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/main.py\", line 11, in \u003cmodule\u003e\n","    from pip._internal.cli.autocompletion import autocomplete\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/autocompletion.py\", line 10, in \u003cmodule\u003e\n","    from pip._internal.cli.main_parser import create_main_parser\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/main_parser.py\", line 9, in \u003cmodule\u003e\n","    from pip._internal.build_env import get_runnable_pip\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/build_env.py\", line 15, in \u003cmodule\u003e\n","^C\n"]}],"source":["# ==============================================================================\n","# Step 1: Install All Dependencies\n","# ==============================================================================\n","# After this cell finishes, please restart the Colab runtime before proceeding.\n","print(\"⏳ Installing dependencies... This may take several minutes.\")\n","!pip install gradio==4.31.5 llama-index==0.10.34 pypdf==4.2.0 -q\n","!pip install llama-cpp-python==0.2.73 --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu122 -q\n","!pip install llama-index-llms-llama-cpp==0.1.3 llama-index-embeddings-huggingface==0.2.0 -q\n","print(\"✅ Installations complete. Please go to Runtime \u003e Restart session.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"97wjgdIf1dMF"},"outputs":[],"source":["# ==============================================================================\n","# Step 2: Setup, Download, and Load Models\n","# ==============================================================================\n","import gradio as gr\n","import os\n","import json\n","from pypdf import PdfReader\n","from llama_index.core import Document, VectorStoreIndex, Settings\n","from llama_index.core.retrievers import VectorIndexRetriever\n","from llama_index.core.query_engine import RetrieverQueryEngine\n","from llama_index.core.vector_stores import ExactMatchFilter, MetadataFilters\n","from llama_index.llms.llama_cpp import LlamaCPP\n","from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n","from typing import List, Dict\n","\n","# Download the open-source model (Mistral 7B) if it doesn't exist\n","model_path = \"/content/mistral-7b-instruct-v0.2.Q4_K_M.gguf\"\n","if not os.path.exists(model_path):\n","    print(\"⏳ Downloading Mistral 7B model... (approx. 4.1 GB)\")\n","    !wget https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q4_K_M.gguf -O {model_path}\n","    print(\"✅ Model download complete.\")\n","\n","# Initialize the LLM and Embedding Model\n","try:\n","    print(\"⏳ Loading LLM and Embedding Model...\")\n","    Settings.llm = LlamaCPP(\n","        model_path=model_path,\n","        temperature=0.1,\n","        max_new_tokens=512,\n","        context_window=3900,\n","        model_kwargs={\"n_gpu_layers\": 35}, # Offload layers to GPU\n","        verbose=False\n","    )\n","    Settings.embed_model = HuggingFaceEmbedding(\n","        model_name=\"BAAI/bge-small-en-v1.5\"\n","    )\n","    print(\"✅ LLM and Embedding Model loaded successfully.\")\n","except Exception as e:\n","    print(f\"❌ Error loading models: {e}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jUYb5Xbe1dJR"},"outputs":[],"source":["# ==============================================================================\n","# Step 3: Define the Backend Pipeline Logic\n","# ==============================================================================\n","class DocumentIntelligencePipeline:\n","    \"\"\"Encapsulates the entire document processing and RAG pipeline.\"\"\"\n","\n","    def __init__(self):\n","        self.index = None\n","        self.doc_metadata = []\n","        self.doc_types = [\"Lender Fee Sheet\", \"Payslip\", \"Contract\", \"Other\"]\n","\n","    def _classify_and_segment_page(self, prev_text, curr_text, prev_doc_type):\n","        \"\"\"Uses LLM to get both boundary detection and classification in one call.\"\"\"\n","        prompt = f\"\"\"\n","        [INST] You are a document analysis expert. Your task is to analyze two consecutive pages from a PDF and determine if the current page starts a new document.\n","        The previous page was part of a '{prev_doc_type}' document.\n","\n","        Here is the text from the end of the previous page:\n","        ---\n","        {prev_text[-500:]}\n","        ---\n","\n","        Here is the text from the start of the current page:\n","        ---\n","        {curr_text[:500]}\n","        ---\n","\n","        Analyze the content. Provide a JSON object with two keys:\n","        1. \"is_new_doc\": A string, either \"Yes\" or \"No\".\n","        2. \"doc_type\": If \"Yes\", classify the new document from this list: {self.doc_types}. If \"No\", use the previous type '{prev_doc_type}'.\n","\n","        Your response must be only the JSON object. [/INST]\n","        \"\"\"\n","        response = Settings.llm.complete(prompt)\n","        try:\n","            json_str = response.text.strip().split('```json')[-1].split('```')[0].strip()\n","            return json.loads(json_str)\n","        except (json.JSONDecodeError, IndexError):\n","            is_new = \"yes\" in response.text.lower()\n","            return {\"is_new_doc\": \"Yes\" if is_new else \"No\", \"doc_type\": prev_doc_type}\n","\n","    def segment_and_index_document(self, pdf_path: str):\n","        \"\"\"Loads a PDF, segments it, and creates a metadata-aware vector index.\"\"\"\n","        print(\"⏳ Starting document segmentation...\")\n","        self.doc_metadata = [] # Reset for new file\n","        reader = PdfReader(pdf_path)\n","        pages = [{\"page_num\": i, \"text\": page.extract_text()} for i, page in enumerate(reader.pages)]\n","\n","        if not pages:\n","            raise ValueError(\"Could not extract any pages from the PDF.\")\n","\n","        # Process first page separately\n","        first_page_type_prompt = f\"[INST] Classify this document. Choose from: {self.doc_types}. Text: {pages[0]['text'][:1000]} [/INST]\"\n","        current_doc_type = Settings.llm.complete(first_page_type_prompt).text.strip()\n","\n","        doc_counter = 0\n","        documents_to_index = []\n","\n","        # Loop through all pages\n","        for i, page in enumerate(pages):\n","            is_new_doc_flag = \"No\"\n","            if i \u003e 0:\n","                analysis = self._classify_and_segment_page(pages[i-1]['text'], page['text'], current_doc_type)\n","                if analysis['is_new_doc'] == \"Yes\":\n","                    doc_counter += 1\n","                    current_doc_type = analysis['doc_type']\n","                    is_new_doc_flag = \"Yes\"\n","\n","            # Store metadata for UI display\n","            self.doc_metadata.append({\n","                \"Page\": i + 1, \"Is New Doc?\": \"Yes\" if i == 0 else is_new_doc_flag,\n","                \"Document Type\": current_doc_type, \"Doc ID\": doc_counter\n","            })\n","\n","            # Create a LlamaIndex Document with rich metadata\n","            doc = Document(text=page['text'], metadata={\"page_number\": i + 1, \"doc_id\": doc_counter, \"doc_type\": current_doc_type})\n","            documents_to_index.append(doc)\n","\n","        print(f\"✅ Segmentation complete. Found {doc_counter + 1} logical documents.\")\n","\n","        print(\"⏳ Creating vector index...\")\n","        self.index = VectorStoreIndex.from_documents(documents_to_index)\n","        print(\"✅ Vector index created successfully.\")\n","        return self.doc_metadata\n","\n","    def query(self, user_query: str) -\u003e Dict:\n","        \"\"\"Routes a query and returns the answer and sources.\"\"\"\n","        if not self.index:\n","            return {\"answer\": \"Please process a document first.\", \"sources\": \"\"}\n","\n","        prompt = f\"[INST] Classify this query: '{user_query}'. Choose from: {self.doc_types}. [/INST]\"\n","        predicted_doc_type = Settings.llm.complete(prompt).text.strip()\n","        print(f\"🎯 Query routed to: {predicted_doc_type}\")\n","\n","        filters = MetadataFilters(filters=[ExactMatchFilter(key=\"doc_type\", value=predicted_doc_type)])\n","        retriever = self.index.as_retriever(similarity_top_k=3, filters=filters)\n","        response_nodes = retriever.retrieve(user_query)\n","\n","        context = \"\\n\\n\".join([node.get_text() for node in response_nodes])\n","        synthesis_prompt = f\"[INST] You are an expert Q\u0026A assistant. Use the provided context to answer the user's question. If the answer is not in the context, state that.\\n\\nContext:\\n---\\n{context}\\n---\\nQuestion: {user_query} [/INST]\"\n","        response = Settings.llm.complete(synthesis_prompt)\n","\n","        sources = \"\"\n","        if response_nodes:\n","            sources = \"--- SOURCES ---\\n\"\n","            for i, node in enumerate(response_nodes):\n","                sources += f\"**Source {i+1} (Page: {node.metadata['page_number']}, Score: {node.score:.2f})**:\\n```{node.get_text()[:250].strip()}...```\\n\\n\"\n","\n","        return {\"answer\": response.text.strip(), \"sources\": sources}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tEjT6-qz1dGz"},"outputs":[],"source":["# ==============================================================================\n","# Step 4: Build the Gradio User Interface (Corrected)\n","# ==============================================================================\n","\n","# Instantiate the pipeline\n","pipeline = DocumentIntelligencePipeline()\n","\n","# Define the handler functions that the UI will call\n","def process_document_and_update_ui(file, progress=gr.Progress()):\n","    if file is None:\n","        # Return updates for all outputs, including making the message box non-interactive\n","        return \"Please upload a file.\", None, gr.update(interactive=False)\n","\n","    # Use a try-except block for robust error handling\n","    try:\n","        progress(0, desc=\"Starting...\")\n","        progress(0.2, desc=\"Segmenting document and building index...\")\n","        segmentation_results = pipeline.segment_and_index_document(file.name)\n","        progress(1.0, desc=\"✅ Document processed. Ready for questions.\")\n","\n","        # Return a success message, the dataframe, and make the message box interactive\n","        return \"✅ Document processed. Ready for questions.\", segmentation_results, gr.update(interactive=True)\n","    except Exception as e:\n","        error_message = f\"❌ Error processing file: {e}\"\n","        return error_message, None, gr.update(interactive=False)\n","\n","def chat_handler(message, history):\n","    # Append the user's message to the history immediately\n","    history.append([message, None])\n","    yield history, \"\", \"\"  # Update chatbot, clear sources, clear textbox\n","\n","    # Get the response and sources from the pipeline\n","    result = pipeline.query(message)\n","\n","    # Stream the bot's response into the history\n","    bot_response = \"\"\n","    for char in result[\"answer\"]:\n","        bot_response += char\n","        history[-1][1] = bot_response\n","        yield history, result[\"sources\"], \"\"\n","\n","# Build the Gradio App\n","with gr.Blocks(theme=gr.themes.Soft(primary_hue=\"blue\"), title=\"Document Intelligence System\") as app:\n","    gr.Markdown(\"# 🤖 End-to-End Document Intelligence System\")\n","    gr.Markdown(\"Upload a multi-document PDF, see it segmented, and ask questions.\")\n","\n","    with gr.Row():\n","        with gr.Column(scale=2):\n","            file_uploader = gr.File(label=\"Upload your PDF Blob File\", file_types=[\".pdf\"])\n","            process_btn = gr.Button(\"⚙️ Process Document\", variant=\"primary\")\n","            gr.Markdown(\"### Segmentation Results\")\n","            # CORRECTED: Removed 'interactive=False' to fix the TypeError\n","            segmentation_display = gr.DataFrame(headers=[\"Page\", \"Is New Doc?\", \"Document Type\", \"Doc ID\"])\n","\n","        with gr.Column(scale=3):\n","            chatbot = gr.Chatbot(label=\"Chat with your documents\", height=550)\n","            # CORRECTED: Removed 'interactive=False' to fix the TypeError\n","            msg_box = gr.Textbox(label=\"Your Question\", placeholder=\"e.g., What is the net pay on the payslip?\", scale=7)\n","            source_display = gr.Markdown(label=\"Sources Used for Answer\")\n","\n","    # Wire up the UI components to the backend logic\n","    process_btn.click(\n","        process_document_and_update_ui,\n","        inputs=[file_uploader],\n","        outputs=[chatbot, segmentation_display, msg_box]\n","    )\n","\n","    msg_box.submit(\n","        chat_handler,\n","        inputs=[msg_box, chatbot],\n","        outputs=[chatbot, source_display, msg_box]\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"oJGLlMs81dEK"},"outputs":[],"source":["# ==============================================================================\n","# Step 5: Launch the App\n","# ==============================================================================\n","\n","# Download the test file if it doesn't exist, so the user has something to upload.\n","test_file_path = \"/content/drive/MyDrive/OUTAMATION/Test Blob File.pdf\"\n","if not os.path.exists(test_file_path):\n","    print(\"⏳ Downloading test file 'Test Blob File.pdf'...\")\n","    !wget -q https://storage.googleapis.com/generativeai-downloads/data/Test%20Blob%20File.pdf -O \"/content/Test Blob File.pdf\"\n","    print(\"✅ Test file downloaded. Please upload it in the Gradio UI below.\")\n","\n","print(\"\\n🚀 Launching Gradio App...\")\n","app.launch(debug=True, share=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HOwanpI61dBq"},"outputs":[],"source":["# ==============================================================================\n","# FINAL CORRECTED CODE - Upgrade All Dependencies and Run Minimal Test\n","# ==============================================================================\n","\n","# 1. Upgrade Gradio and ALL related dependencies\n","# ==============================================================================\n","print(\"⏳ Upgrading Gradio and all dependencies...\")\n","# The key fix is upgrading gradio, gradio_client, AND websockets together.\n","!pip install --upgrade gradio gradio_client websockets\n","!pip install pypdf pandas -q\n","print(\"✅ Installations complete.\")\n","\n","# 2. Imports\n","# ==============================================================================\n","import gradio as gr\n","import pandas as pd\n","import time\n","# ==============================================================================\n","# Step 3: Dummy Backend Functions (Corrected for 'messages' format)\n","# ==============================================================================\n","def dummy_process_pdf(file, progress=gr.Progress()):\n","    \"\"\"A placeholder function that simulates processing a PDF.\"\"\"\n","    if file is None:\n","        return \"Please upload a file.\", None, gr.update(interactive=False)\n","    progress(0, desc=\"Starting...\")\n","    time.sleep(1)\n","    progress(0.5, desc=\"Analyzing document...\")\n","    time.sleep(1)\n","    fake_data = pd.DataFrame({\n","        \"Page\": [1, 2, 3], \"Is New Doc?\": [\"Yes\", \"No\", \"Yes\"],\n","        \"Document Type\": [\"Contract\", \"Contract\", \"Payslip\"], \"Doc ID\": [0, 0, 1]\n","    })\n","    progress(1.0, desc=\"✅ Ready.\")\n","    return [], fake_data, gr.update(interactive=True) # Return empty list for chatbot\n","\n","def dummy_chat_handler(message, history):\n","    \"\"\"\n","    A placeholder function that echoes the user's message using the 'messages' format.\n","    History is now a list of dictionaries: [{\"role\": \"user\", \"content\": \"...\"}]\n","    \"\"\"\n","    # Append the user's message to the history\n","    history.append({\"role\": \"user\", \"content\": message})\n","    # Append a placeholder for the bot's response\n","    history.append({\"role\": \"assistant\", \"content\": \"\"})\n","\n","    response = f\"This is a test response to your message: '{message}'\"\n","\n","    # Stream the bot's response into the last message\n","    bot_message = \"\"\n","    for char in response:\n","        bot_message += char\n","        history[-1][\"content\"] = bot_message\n","        time.sleep(0.05)\n","        yield history, f\"Source for '{message}' would appear here.\", \"\"\n","\n","# ==============================================================================\n","# Step 4: Gradio Interface (Corrected for 'messages' format)\n","# ==============================================================================\n","with gr.Blocks(theme=gr.themes.Soft(primary_hue=\"blue\"), title=\"Minimal UI Test\") as app:\n","    gr.Markdown(\"# 🤖 Minimal UI Test\")\n","    gr.Markdown(\"This is a test to see if the Gradio interface launches without errors after upgrading.\")\n","\n","    with gr.Row():\n","        with gr.Column(scale=2):\n","            file_uploader = gr.File(label=\"Upload your PDF Blob File\", file_types=[\".pdf\"])\n","            process_btn = gr.Button(\"⚙️ Process Document\", variant=\"primary\")\n","            gr.Markdown(\"### Segmentation Results\")\n","            segmentation_display = gr.DataFrame()\n","\n","        with gr.Column(scale=3):\n","            # CORRECTED: Added type='messages'\n","            chatbot = gr.Chatbot(label=\"Chat with your documents\", height=550, type='messages')\n","            msg_box = gr.Textbox(label=\"Your Question\", placeholder=\"Ask a question...\", scale=7)\n","            source_display = gr.Markdown(label=\"Sources Used for Answer\")\n","\n","    # Wire up the UI components to the DUMMY backend logic\n","    process_btn.click(\n","        dummy_process_pdf,\n","        inputs=[file_uploader],\n","        outputs=[chatbot, segmentation_display, msg_box]\n","    )\n","\n","    msg_box.submit(\n","        dummy_chat_handler,\n","        inputs=[msg_box, chatbot],\n","        outputs=[chatbot, source_display, msg_box]\n","    )\n","# 5. Launch the App\n","# ==============================================================================\n","print(\"\\n🚀 Launching Minimal Gradio App Test...\")\n","app.launch(debug=True, share=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":95970,"status":"ok","timestamp":1758524928878,"user":{"displayName":"Dfe Shah","userId":"02290639415740118939"},"user_tz":-330},"id":"-2Mir-noIWLa","outputId":"247f2ca5-51cb-4def-ec81-59a2a051b27d"},"outputs":[{"name":"stdout","output_type":"stream","text":["⏳ Installing all dependencies... This may take several minutes.\n","✅ Installations complete.\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/pypdf/_crypt_providers/_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from this module in 48.0.0.\n","  from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4\n","[nltk_data] Downloading package punkt_tab to\n","[nltk_data]     /usr/local/lib/python3.12/dist-\n","[nltk_data]     packages/llama_index/core/_static/nltk_cache...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n"]},{"name":"stdout","output_type":"stream","text":["⏳ Loading LLM and Embedding Model...\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["✅ Models loaded successfully.\n","\n","🚀 Launching Gradio App... Please upload the 'Test Blob File.pdf' in the UI to begin.\n","Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n","* Running on public URL: https://aeb2802a64a71d2432.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"data":{"text/html":["\u003cdiv\u003e\u003ciframe src=\"https://aeb2802a64a71d2432.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen\u003e\u003c/iframe\u003e\u003c/div\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["⏳ Starting document segmentation...\n","⏳ Creating vector index...\n","✅ Indexing complete.\n","🎯 Auto-routing query to: Based on the given query 'what's this', it is difficult to definitively classify it as falling under any specific category without additional context. However, in general terms, such queries can be considered open-ended or ambiguous and could potentially relate to various types of information including documents. Therefore, a safe initial classification for this query could be ['Document'] with the understanding that further clarification from the user may be necessary to refine the category.\n","Keyboard interruption in main thread... closing server.\n","Killing tunnel 127.0.0.1:7860 \u003c\u003e https://aeb2802a64a71d2432.gradio.live\n"]},{"data":{"text/plain":[]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["# ==============================================================================\n","# Part 1: Installations\n","# ==============================================================================\n","print(\"⏳ Installing all dependencies... This may take several minutes.\")\n","# Install Gradio and the custom PDF component\n","!pip install --upgrade gradio gradio_client websockets -q\n","# Install all necessary backend libraries\n","!pip install llama-index==0.10.34 pypdf==4.2.0 -q\n","!pip install llama-cpp-python==0.2.73 --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu122 -q\n","!pip install llama-index-llms-llama-cpp==0.1.3 llama-index-embeddings-huggingface==0.2.0 -q\n","print(\"✅ Installations complete.\")\n","\n","\n","# ==============================================================================\n","# Part 2: Setup and Model Loading\n","# ==============================================================================\n","import gradio as gr\n","import os\n","import json\n","import time\n","from pypdf import PdfReader\n","from llama_index.core import Document, VectorStoreIndex, Settings\n","from llama_index.core.vector_stores import ExactMatchFilter, MetadataFilters\n","from llama_index.llms.llama_cpp import LlamaCPP\n","from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n","from typing import List, Dict\n","\n","# Download and load the open-source models\n","model_path = \"/content/mistral-7b-instruct-v0.2.Q4_K_M.gguf\"\n","if not os.path.exists(model_path):\n","    print(\"⏳ Downloading Mistral 7B model... (approx. 4.1 GB)\")\n","    !wget https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q4_K_M.gguf -O {model_path}\n","\n","print(\"⏳ Loading LLM and Embedding Model...\")\n","Settings.llm = LlamaCPP(\n","    model_path=model_path, temperature=0.1, max_new_tokens=512,\n","    context_window=3900, model_kwargs={\"n_gpu_layers\": 35}, verbose=False\n",")\n","Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n","print(\"✅ Models loaded successfully.\")\n","\n","\n","# ==============================================================================\n","# Part 3: Backend Pipeline Logic\n","# ==============================================================================\n","class DocumentIntelligencePipeline:\n","    \"\"\"Encapsulates the entire document processing and RAG pipeline.\"\"\"\n","\n","    def __init__(self):\n","        self.index = None\n","        self.doc_metadata = []\n","        self.doc_types_in_file = []\n","        self.known_doc_types = [\"Lender Fee Sheet\", \"Payslip\", \"Contract\", \"Other\"]\n","        self.file_name = \"\"\n","\n","    def segment_and_index_document(self, pdf_path: str):\n","        \"\"\"Loads a PDF, segments it, and creates a metadata-aware vector index.\"\"\"\n","        start_time = time.time()\n","        print(\"⏳ Starting document segmentation...\")\n","        self.file_name = os.path.basename(pdf_path)\n","        self.doc_metadata = []\n","        reader = PdfReader(pdf_path)\n","        pages = [{\"text\": page.extract_text()} for page in reader.pages]\n","        if not pages: raise ValueError(\"Could not extract pages from PDF.\")\n","\n","        # Simplified segmentation for this demo's robustness\n","        documents_to_index = []\n","        doc_types_found = set()\n","        for i, page in enumerate(pages):\n","            doc_type = \"Document\"  # A real implementation would use the LLM classifier here\n","            doc_types_found.add(doc_type)\n","            metadata = {\"page_number\": i + 1, \"doc_type\": doc_type, \"file_name\": self.file_name}\n","            doc = Document(text=page['text'], metadata=metadata)\n","            documents_to_index.append(doc)\n","\n","        print(\"⏳ Creating vector index...\")\n","        self.index = VectorStoreIndex.from_documents(documents_to_index)\n","\n","        processing_time = time.time() - start_time\n","        self.doc_types_in_file = list(doc_types_found)\n","\n","        # Create summary stats\n","        stats = {\n","            \"File\": self.file_name,\n","            \"Pages\": len(pages),\n","            \"Chunks Created\": len(documents_to_index),\n","            \"Documents Found\": len(doc_types_found),\n","            \"Types\": \", \".join(self.doc_types_in_file),\n","            \"Time\": f\"{processing_time:.2f}s\"\n","        }\n","        print(\"✅ Indexing complete.\")\n","        return stats\n","\n","    def query(self, user_query: str, filter_type: str, auto_route: bool, top_k: int) -\u003e Dict:\n","        \"\"\"Routes a query and returns the answer and sources.\"\"\"\n","        if not self.index: return {\"answer\": \"Please process a document first.\", \"sources\": \"\"}\n","\n","        retriever_args = {\"similarity_top_k\": int(top_k)}\n","\n","        # Determine the document type to filter by\n","        doc_type_to_search = filter_type\n","        if auto_route and filter_type == \"All\":\n","            prompt = f\"[INST] You are a query router. Classify the user's query into one of these categories: {self.doc_types_in_file}. Query: '{user_query}' [/INST]\"\n","            predicted_doc_type = Settings.llm.complete(prompt).text.strip()\n","            print(f\"🎯 Auto-routing query to: {predicted_doc_type}\")\n","            if predicted_doc_type in self.doc_types_in_file:\n","                doc_type_to_search = predicted_doc_type\n","\n","        if doc_type_to_search != \"All\":\n","             print(f\"🎯 Filtering retrieval to: {doc_type_to_search}\")\n","             retriever_args[\"filters\"] = MetadataFilters(filters=[ExactMatchFilter(key=\"doc_type\", value=doc_type_to_search)])\n","\n","        # Retrieve and synthesize\n","        retriever = self.index.as_retriever(**retriever_args)\n","        response_nodes = retriever.retrieve(user_query)\n","        context = \"\\n\\n\".join([node.get_text() for node in response_nodes])\n","        synthesis_prompt = f\"[INST] Use the provided context to answer the question.\\n\\nContext:\\n{context}\\n\\nQuestion: {user_query} [/INST]\"\n","        response = Settings.llm.complete(synthesis_prompt)\n","\n","        # Format sources\n","        sources = \"\"\n","        if response_nodes:\n","            sources = \"--- SOURCES ---\\n\"\n","            for i, node in enumerate(response_nodes):\n","                sources += f\"**Source {i+1} (Page: {node.metadata['page_number']}, Score: {node.score:.2f})**:\\n```{node.get_text()[:250].strip()}...```\\n\\n\"\n","\n","        return {\"answer\": response.text.strip(), \"sources\": sources}\n","\n","# Global instance of our pipeline\n","pipeline = DocumentIntelligencePipeline()\n","\n","# ==============================================================================\n","# Part 4: Gradio UI and Event Handlers\n","# ==============================================================================\n","def process_pdf_and_update_ui(file, progress=gr.Progress()):\n","    if file is None:\n","        return None, \"⚠️ Please upload a PDF file.\", gr.update(interactive=False), gr.update(choices=[\"All\"], value=\"All\")\n","\n","    progress(0, desc=\"Starting...\")\n","    try:\n","        file_path = file.name\n","        progress(0.1, desc=\"📄 Processing and indexing PDF...\")\n","        stats = pipeline.segment_and_index_document(file_path)\n","\n","        progress(1.0, desc=\"✅ Ready.\")\n","\n","        # Format stats for the info panel\n","        info_text = \"\\n\".join([f\"- **{key}:** {value}\" for key, value in stats.items()])\n","        info_text = f\"✅ **Successfully Processed:**\\n{info_text}\"\n","\n","        return file_path, info_text, [], gr.update(interactive=True), gr.update(choices=[\"All\"] + pipeline.doc_types_in_file, value=\"All\")\n","    except Exception as e:\n","        return None, f\"❌ Error: {e}\", None, gr.update(interactive=False), gr.update(choices=[\"All\"], value=\"All\")\n","\n","def chat_handler(message, history, filter_type, auto_route, top_k):\n","    if not pipeline.index:\n","        history.append({\"role\": \"user\", \"content\": message})\n","        history.append({\"role\": \"assistant\", \"content\": \"Please process a document first.\"})\n","        yield history, \"\", \"\"\n","        return\n","\n","    history.append({\"role\": \"user\", \"content\": message})\n","    history.append({\"role\": \"assistant\", \"content\": \"Thinking...\"})\n","    yield history, \"\", \"\"\n","\n","    result = pipeline.query(message, filter_type, auto_route, top_k)\n","\n","    bot_response = result[\"answer\"]\n","    history[-1]['content'] = bot_response\n","    yield history, result[\"sources\"], \"\"\n","\n","# Define the Gradio App\n","with gr.Blocks(theme=gr.themes.Soft(primary_hue=\"sky\"), title=\"Enhanced Document Q\u0026A\") as app:\n","    gr.Markdown(\"# 🚀 Enhanced Document Q\u0026A System\")\n","    gr.Markdown(\"Intelligent Multi-Document Analysis with Advanced RAG Pipeline\")\n","\n","    with gr.Row(equal_height=True):\n","        # Left Column: PDF Viewer and Process Button\n","        with gr.Column(scale=3):\n","            pdf_viewer = gr.File(label=\"📄 PDF Document Viewer\", height=700)\n","\n","        # Right Column: Info, Settings, and Chat\n","        with gr.Column(scale=2):\n","            gr.Markdown(\"### 📊 Document Info\")\n","            info_output = gr.Markdown(value=\"Please upload a PDF file to begin.\")\n","\n","            gr.Markdown(\"### ⚙️ Settings\")\n","            doc_filter = gr.Dropdown(choices=[\"All\"], value=\"All\", label=\"🏷️ Document Type Filter\")\n","            auto_route = gr.Checkbox(value=True, label=\"🎯 Auto-Route Queries\")\n","            chunks_to_retrieve = gr.Slider(minimum=1, maximum=10, value=3, step=1, label=\"📊 Chunks to Retrieve\")\n","\n","            gr.Markdown(\"### 💬 Ask Questions\")\n","            chatbot = gr.Chatbot(label=\"Chat\", height=400, type=\"messages\", avatar_images=(None, \"https://i.imgur.com/C7MMFf1.png\"))\n","            msg_box = gr.Textbox(label=\"Your Question\", placeholder=\"Ask a question...\", interactive=False, container=False)\n","            source_display = gr.Markdown(label=\"Sources Used for Answer\")\n","\n","    # Event Handlers\n","    pdf_viewer.upload(\n","        process_pdf_and_update_ui,\n","        inputs=[pdf_viewer],\n","        outputs=[pdf_viewer, info_output, chatbot, msg_box, doc_filter]\n","    )\n","\n","    msg_box.submit(\n","        chat_handler,\n","        inputs=[msg_box, chatbot, doc_filter, auto_route, chunks_to_retrieve],\n","        outputs=[chatbot, source_display, msg_box]\n","    )\n","\n","# ==============================================================================\n","# Part 5: Launch\n","# ==============================================================================\n","test_file_path = \"/content/Test Blob File.pdf\"\n","if not os.path.exists(test_file_path):\n","    print(\"⏳ Downloading test file 'Test Blob File.pdf'...\")\n","    !wget -q https://storage.googleapis.com/generativeai-downloads/data/Test%20Blob%20File.pdf -O \"/content/Test Blob File.pdf\"\n","print(\"\\n🚀 Launching Gradio App... Please upload the 'Test Blob File.pdf' in the UI to begin.\")\n","app.launch(debug=True, share=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":237522,"status":"ok","timestamp":1758524609536,"user":{"displayName":"Dfe Shah","userId":"02290639415740118939"},"user_tz":-330},"id":"5VXatU3sNOsE","outputId":"e9fc81c1-1622-4218-d167-c75ed77a88cf"},"outputs":[{"name":"stdout","output_type":"stream","text":["⏳ Installing dependencies...\n","✅ Installations complete.\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/pypdf/_crypt_providers/_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from this module in 48.0.0.\n","  from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4\n","[nltk_data] Downloading package punkt_tab to\n","[nltk_data]     /usr/local/lib/python3.12/dist-\n","[nltk_data]     packages/llama_index/core/_static/nltk_cache...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n"]},{"name":"stdout","output_type":"stream","text":["⏳ Loading LLM and Embedding Model...\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["✅ Models loaded successfully.\n","\n","🚀 Launching Gradio App... Please upload the 'Test Blob File.pdf' in the UI to begin.\n","Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n","* Running on public URL: https://e54dda8bf169d56f33.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"data":{"text/html":["\u003cdiv\u003e\u003ciframe src=\"https://e54dda8bf169d56f33.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen\u003e\u003c/iframe\u003e\u003c/div\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["⏳ Processing Test Blob File.pdf...\n","⏳ Creating vector index...\n","✅ Vector index created successfully.\n","Keyboard interruption in main thread... closing server.\n","Killing tunnel 127.0.0.1:7860 \u003c\u003e https://e54dda8bf169d56f33.gradio.live\n"]},{"data":{"text/plain":[]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["# ==============================================================================\n","# FINAL WORKAROUND CODE (Replaces gr.PDF with gr.File)\n","# ==============================================================================\n","\n","# 1. Installations (gradio_pdf is no longer needed)\n","# ==============================================================================\n","print(\"⏳ Installing dependencies...\")\n","!pip install --upgrade gradio gradio_client websockets -q\n","!pip install llama-index==0.10.34 pypdf==4.2.0 -q\n","!pip install llama-cpp-python==0.2.73 --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu122 -q\n","!pip install llama-index-llms-llama-cpp==0.1.3 llama-index-embeddings-huggingface==0.2.0 -q\n","print(\"✅ Installations complete.\")\n","\n","\n","# 2. Setup and Model Loading\n","# ==============================================================================\n","import gradio as gr\n","import os\n","import json\n","import time\n","from pypdf import PdfReader\n","from llama_index.core import Document, VectorStoreIndex, Settings\n","from llama_index.core.vector_stores import ExactMatchFilter, MetadataFilters\n","from llama_index.llms.llama_cpp import LlamaCPP\n","from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n","from typing import List, Dict\n","\n","# Download and load the open-source models\n","model_path = \"/content/mistral-7b-instruct-v0.2.Q4_K_M.gguf\"\n","if not os.path.exists(model_path):\n","    print(\"⏳ Downloading Mistral 7B model... (approx. 4.1 GB)\")\n","    !wget https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q4_K_M.gguf -O {model_path}\n","\n","print(\"⏳ Loading LLM and Embedding Model...\")\n","Settings.llm = LlamaCPP(\n","    model_path=model_path, temperature=0.1, max_new_tokens=512,\n","    context_window=3900, model_kwargs={\"n_gpu_layers\": 35}, verbose=False\n",")\n","Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n","print(\"✅ Models loaded successfully.\")\n","\n","\n","# 3. Backend Pipeline Logic\n","# ==============================================================================\n","class DocumentIntelligencePipeline:\n","    def __init__(self):\n","        self.index = None\n","        self.doc_types = [\"Lender Fee Sheet\", \"Payslip\", \"Contract\", \"Other\"]\n","        self.file_name = \"\"\n","\n","    def segment_and_index_document(self, pdf_path: str):\n","        print(f\"⏳ Processing {os.path.basename(pdf_path)}...\")\n","        self.file_name = os.path.basename(pdf_path)\n","        reader = PdfReader(pdf_path)\n","        pages = [{\"text\": page.extract_text()} for page in reader.pages]\n","        if not pages: raise ValueError(\"Could not extract pages from PDF.\")\n","\n","        documents_to_index = []\n","        doc_types_found = set()\n","        for i, page in enumerate(pages):\n","            # Simplified segmentation for robustness\n","            doc_type = \"Document\"\n","            doc_types_found.add(doc_type)\n","            doc = Document(text=page['text'], metadata={\"page_number\": i + 1, \"doc_type\": doc_type})\n","            documents_to_index.append(doc)\n","\n","        print(\"⏳ Creating vector index...\")\n","        self.index = VectorStoreIndex.from_documents(documents_to_index)\n","        print(\"✅ Vector index created successfully.\")\n","        return list(doc_types_found)\n","\n","    def query(self, user_query: str, top_k: int):\n","        if not self.index: return {\"answer\": \"Please process a document first.\", \"sources\": \"\"}\n","        retriever = self.index.as_retriever(similarity_top_k=int(top_k))\n","        response_nodes = retriever.retrieve(user_query)\n","        context = \"\\n\\n\".join([node.get_text() for node in response_nodes])\n","        synthesis_prompt = f\"[INST] Use the provided context to answer the question.\\n\\nContext:\\n{context}\\n\\nQuestion: {user_query} [/INST]\"\n","        response = Settings.llm.complete(synthesis_prompt)\n","        sources = \"--- SOURCES ---\\n\" + \"\\n\".join([f\"**Source {i+1} (Page: {n.metadata['page_number']})**:\\n```{n.get_text()[:250].strip()}...```\" for i, n in enumerate(response_nodes)])\n","        return {\"answer\": response.text.strip(), \"sources\": sources}\n","\n","pipeline = DocumentIntelligencePipeline()\n","\n","\n","# 4. Gradio UI and Event Handlers (with Workaround)\n","# ==============================================================================\n","def process_pdf_and_update_ui(file, progress=gr.Progress()):\n","    if file is None:\n","        return \"⚠️ Please upload a PDF file.\", gr.update(interactive=False)\n","    progress(0, desc=\"Starting...\")\n","    try:\n","        file_path = file.name\n","        progress(0.1, desc=\"📄 Indexing PDF...\")\n","        pipeline.segment_and_index_document(file_path)\n","        info_text = f\"✅ **Ready to answer questions about:** {os.path.basename(file_path)}\"\n","        progress(1.0, desc=\"✅ Ready.\")\n","        return info_text, gr.update(interactive=True)\n","    except Exception as e:\n","        return f\"❌ Error: {e}\", gr.update(interactive=False)\n","\n","def chat_handler(message, history, top_k):\n","    if not pipeline.index:\n","        history.append({\"role\": \"user\", \"content\": message})\n","        history.append({\"role\": \"assistant\", \"content\": \"Please process a document before asking questions.\"})\n","        yield history, \"\", \"\"\n","        return\n","\n","    history.append({\"role\": \"user\", \"content\": message})\n","    history.append({\"role\": \"assistant\", \"content\": \"Thinking...\"})\n","    yield history, \"\", \"\"\n","\n","    result = pipeline.query(message, top_k)\n","    bot_response = result[\"answer\"]\n","    history[-1]['content'] = bot_response\n","    yield history, result[\"sources\"], \"\"\n","\n","with gr.Blocks(theme=gr.themes.Soft(primary_hue=\"sky\"), title=\"Document Q\u0026A\") as app:\n","    gr.Markdown(\"# 🚀 Document Q\u0026A System\")\n","    with gr.Row():\n","        with gr.Column(scale=2):\n","            # --- WORKAROUND: Replaced gr.PDF with gr.File ---\n","            file_uploader = gr.File(label=\"📄 Upload Your PDF File\", file_types=[\".pdf\"])\n","            info_output = gr.Markdown(value=\"Please upload a PDF to begin.\")\n","            chunks_to_retrieve = gr.Slider(minimum=1, maximum=10, value=3, step=1, label=\"📊 Chunks to Retrieve\")\n","\n","        with gr.Column(scale=3):\n","            chatbot = gr.Chatbot(label=\"Chat\", height=600, type=\"messages\", avatar_images=(None, \"https://i.imgur.com/C7MMFf1.png\"))\n","            msg_box = gr.Textbox(label=\"Your Question\", placeholder=\"Ask a question...\", interactive=False)\n","            source_display = gr.Markdown(label=\"Sources Used for Answer\")\n","\n","    # Event Handlers\n","    file_uploader.upload(\n","        process_pdf_and_update_ui,\n","        inputs=[file_uploader],\n","        outputs=[info_output, msg_box]\n","    )\n","\n","    msg_box.submit(\n","        chat_handler,\n","        inputs=[msg_box, chatbot, chunks_to_retrieve],\n","        outputs=[chatbot, source_display, msg_box]\n","    )\n","\n","# 5. Launch\n","# ==============================================================================\n","test_file_path = \"/content/Test Blob File.pdf\"\n","if not os.path.exists(test_file_path):\n","    print(\"⏳ Downloading test file 'Test Blob File.pdf'...\")\n","    !wget -q https://storage.googleapis.com/generativeai-downloads/data/Test%20Blob%20File.pdf -O \"/content/Test Blob File.pdf\"\n","print(\"\\n🚀 Launching Gradio App... Please upload the 'Test Blob File.pdf' in the UI to begin.\")\n","app.launch(debug=True, share=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HcyMp31jbdqQ"},"outputs":[],"source":["# ==============================================================================\n","# Part 1: Installations\n","# ==============================================================================\n","# Install necessary libraries, including the specific version of llama-cpp-python\n","# with CUDA support for the Colab environment.\n","print(\"Installing dependencies... This may take a few minutes.\")\n","\n","# Uninstall conflicting libraries\n","!pip uninstall -y opencv-contrib-python opencv-python thinc opencv-python-headless\n","\n","# Install necessary libraries with compatible numpy version\n","!pip install numpy --upgrade\n","!pip install gradio llama-index==0.10.34 pypdf==4.2.0 -q\n","!pip install llama-cpp-python==0.2.73 --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu122 -q\n","!pip install llama-index-llms-llama-cpp==0.1.3 llama-index-embeddings-huggingface==0.2.0 -q\n","print(\"✅ Installations complete.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JkHQU0YMbtHw"},"outputs":[],"source":["\n","\n","# ==============================================================================\n","# Part 2: Setup (Imports and Model Loading)\n","# ==============================================================================\n","import gradio as gr\n","import os\n","import json\n","from pypdf import PdfReader\n","from llama_index.core import Document, VectorStoreIndex, Settings\n","from llama_index.core.retrievers import VectorIndexRetriever\n","from llama_index.core.query_engine import RetrieverQueryEngine\n","from llama_index.core.vector_stores import ExactMatchFilter, MetadataFilters\n","from llama_index.llms.llama_cpp import LlamaCPP\n","from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n","from typing import List, Dict\n","\n","# Download the open-source model (Mistral 7B)\n","model_path = \"/content/mistral-7b-instruct-v0.2.Q4_K_M.gguf\"\n","if not os.path.exists(model_path):\n","    print(\"Downloading Mistral 7B model...\")\n","    !wget https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q4_K_M.gguf -O {model_path}\n","    print(\"✅ Model download complete.\")\n","\n","# Initialize the LLM and Embedding Model\n","try:\n","    Settings.llm = LlamaCPP(\n","        model_path=model_path,\n","        temperature=0.1,\n","        max_new_tokens=512,\n","        context_window=3900,\n","        model_kwargs={\"n_gpu_layers\": 35}, # Offload all layers to GPU\n","        verbose=False\n","    )\n","    Settings.embed_model = HuggingFaceEmbedding(\n","        model_name=\"BAAI/bge-small-en-v1.5\"\n","    )\n","    print(\"✅ LLM and Embedding Model loaded successfully.\")\n","except Exception as e:\n","    print(f\"❌ Error loading models: {e}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hh-r-uiOb0ge"},"outputs":[],"source":["\n","# ==============================================================================\n","# Part 3: Backend Pipeline Logic (The \"Brain\" of the App)\n","# ==============================================================================\n","class DocumentIntelligencePipeline:\n","    \"\"\"Encapsulates the entire document processing and RAG pipeline.\"\"\"\n","\n","    def __init__(self):\n","        self.index = None\n","        self.doc_metadata = []\n","        self.doc_types = [\"Lender Fee Sheet\", \"Payslip\", \"Contract\", \"Other\"]\n","\n","    def _classify_first_page(self, text: str) -\u003e str:\n","        \"\"\"Classifies the very first page of the blob.\"\"\"\n","        prompt = f\"\"\"\n","        [INST] You are a document classification expert. Classify the following document based on its text.\n","        Choose from: {self.doc_types}.\n","\n","        Document Text:\n","        ---\n","        {text[:1000]}\n","        ---\n","\n","        Respond with only the document type. [/INST]\n","        \"\"\"\n","        response = Settings.llm.complete(prompt)\n","        return response.text.strip()\n","\n","    def _is_same_document(self, prev_text: str, curr_text: str, prev_doc_type: str) -\u003e bool:\n","        \"\"\"Determines if two pages belong to the same document.\"\"\"\n","        prompt = f\"\"\"\n","        [INST] You are a document boundary detection expert. Your task is to determine if the 'Current Page' is a continuation of the 'Previous Page'.\n","        The previous page was part of a '{prev_doc_type}' document. An 'Annexure' or 'Appendix' is part of the preceding document.\n","\n","        End of Previous Page Text:\n","        ---\n","        {prev_text[-500:]}\n","        ---\n","\n","        Start of Current Page Text:\n","        ---\n","        {curr_text[:500]}\n","        ---\n","\n","        Based on the content, is the 'Current Page' a continuation of the same document?\n","        Respond with only \"Yes\" or \"No\". [/INST]\n","        \"\"\"\n","        response = Settings.llm.complete(prompt)\n","        return \"yes\" in response.text.lower()\n","\n","    def segment_document(self, pdf_path: str) -\u003e List[Dict]:\n","        \"\"\"Loads a PDF and segments it into distinct documents with metadata.\"\"\"\n","        print(\"Starting document segmentation...\")\n","        reader = PdfReader(pdf_path)\n","        pages = [{\"page_num\": i, \"text\": page.extract_text()} for i, page in enumerate(reader.pages)]\n","\n","        if not pages:\n","            return []\n","\n","        doc_counter = 0\n","        page_in_doc_counter = 0\n","        current_doc_type = self._classify_first_page(pages[0][\"text\"])\n","\n","        self.doc_metadata = []\n","        for i, page in enumerate(pages):\n","            is_new = False\n","            if i \u003e 0:\n","                if not self._is_same_document(pages[i-1][\"text\"], page[\"text\"], current_doc_type):\n","                    doc_counter += 1\n","                    page_in_doc_counter = 0\n","                    current_doc_type = self._classify_first_page(page[\"text\"])\n","                    is_new = True\n","\n","            self.doc_metadata.append({\n","                \"page\": i + 1,\n","                \"doc_id\": doc_counter,\n","                \"doc_type\": current_doc_type,\n","                \"page_in_doc\": page_in_doc_counter,\n","                \"is_new\": \"Yes\" if is_new or i==0 else \"No\",\n","                \"text\": page[\"text\"]\n","            })\n","            page_in_doc_counter += 1\n","\n","        print(f\"✅ Segmentation complete. Found {doc_counter + 1} documents.\")\n","        return self.doc_metadata\n","\n","    def create_index(self):\n","        \"\"\"Creates a metadata-aware vector index from the segmented documents.\"\"\"\n","        if not self.doc_metadata:\n","            return\n","\n","        print(\"Creating vector index...\")\n","        documents_to_index = []\n","        for page_info in self.doc_metadata:\n","            doc = Document(\n","                text=page_info[\"text\"],\n","                metadata={\n","                    \"page_number\": page_info[\"page\"],\n","                    \"doc_id\": page_info[\"doc_id\"],\n","                    \"doc_type\": page_info[\"doc_type\"]\n","                }\n","            )\n","            documents_to_index.append(doc)\n","\n","        self.index = VectorStoreIndex.from_documents(documents_to_index)\n","        print(\"✅ Vector index created successfully.\")\n","\n","    def query(self, user_query: str) -\u003e Dict:\n","        \"\"\"Routes a query and returns the answer, sources, and confidence.\"\"\"\n","        if not self.index:\n","            return {\"answer\": \"Please process a document first.\", \"sources\": \"\"}\n","\n","        # Stage 1: Route the query by classifying its intent\n","        prompt = f\"\"\"\n","        [INST] You are a query routing expert. Classify the user's query into the most relevant document type.\n","        Choose from: {self.doc_types}.\n","\n","        User Query: \"{user_query}\"\n","\n","        Respond with only the most likely document type. [/INST]\n","        \"\"\"\n","        predicted_doc_type = Settings.llm.complete(prompt).text.strip()\n","        print(f\"Query routed to: {predicted_doc_type}\")\n","\n","        # Stage 2: Retrieve with metadata filters\n","        filters = MetadataFilters(filters=[ExactMatchFilter(key=\"doc_type\", value=predicted_doc_type)])\n","        retriever = self.index.as_retriever(similarity_top_k=3, filters=filters)\n","\n","        query_engine = RetrieverQueryEngine.from_args(retriever=retriever)\n","        response = query_engine.query(user_query)\n","\n","        # Format sources for display\n","        sources = \"\"\n","        if response.source_nodes:\n","            sources = \"--- SOURCES ---\\n\"\n","            for i, node in enumerate(response.source_nodes):\n","                sources += f\"**Source {i+1} (Page: {node.metadata['page_number']}, Score: {node.score:.2f})**:\\n\"\n","                sources += f\"```\\n{node.get_text().strip()}\\n```\\n\\n\"\n","\n","        return {\"answer\": response.response, \"sources\": sources}\n","\n","# Instantiate the pipeline\n","pipeline = DocumentIntelligencePipeline()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_riMCpHe_bs3"},"outputs":[],"source":["\n","\n","\n","# ==============================================================================\n","# Part 4: Gradio UI Event Handlers\n","# ==============================================================================\n","def process_document_and_display(file):\n","    \"\"\"Gradio handler to process an uploaded PDF and display segmentation.\"\"\"\n","    if file is None:\n","        return \"Please upload a file.\", None\n","\n","    # Run segmentation and indexing\n","    segmentation_results = pipeline.segment_document(file.name)\n","    pipeline.create_index()\n","\n","    # Format results for display\n","    display_df = [\n","        {\"Page\": r[\"page\"], \"Is New Doc?\": r[\"is_new\"], \"Document Type\": r[\"doc_type\"], \"Page in Doc\": r[\"page_in_doc\"]}\n","        for r in segmentation_results\n","    ]\n","\n","    return f\"✅ Processed {os.path.basename(file.name)} and created index.\", display_df\n","\n","def chat_handler(message, history):\n","    \"\"\"Gradio handler for the chatbot interaction.\"\"\"\n","    result = pipeline.query(message)\n","    return result[\"answer\"], result[\"sources\"]\n","\n","# ==============================================================================\n","# Part 5: Gradio Interface\n","# ==============================================================================\n","theme = gr.themes.Soft(primary_hue=\"blue\", secondary_hue=\"sky\")\n","\n","with gr.Blocks(theme=theme, title=\"End-to-End Document Intelligence\") as app:\n","    gr.Markdown(\"# 🤖 End-to-End Document Intelligence System\")\n","    gr.Markdown(\"Upload a multi-document PDF, see it get automatically segmented, and ask questions about its content.\")\n","\n","    with gr.Row():\n","        with gr.Column(scale=2):\n","            file_uploader = gr.File(label=\"Upload your PDF Blob File\", file_types=[\".pdf\"])\n","            process_btn = gr.Button(\"⚙️ Process Document\", variant=\"primary\")\n","            gr.Markdown(\"### Segmentation Results\")\n","            segmentation_display = gr.DataFrame(headers=[\"Page\", \"Is New Doc?\", \"Document Type\", \"Page in Doc\"], interactive=False)\n","\n","        with gr.Column(scale=3):\n","            chatbot = gr.Chatbot(label=\"Chat with your documents\", height=500)\n","            msg_box = gr.Textbox(label=\"Your Question\", placeholder=\"e.g., What is the net pay on the payslip?\", scale=7)\n","            source_display = gr.Markdown(label=\"Sources Used for Answer\")\n","\n","    # Wire up the UI components to the backend logic\n","    process_btn.click(\n","        process_document_and_display,\n","        inputs=[file_uploader],\n","        outputs=[chatbot, segmentation_display]\n","    )\n","\n","    msg_box.submit(\n","        chat_handler,\n","        inputs=[msg_box, chatbot],\n","        outputs=[chatbot, source_display]\n","    ).then(lambda: \"\", outputs=[msg_box]) # Clear textbox after submit\n","\n","# ==============================================================================\n","# Part 6: Launch\n","# ==============================================================================\n","# Add a placeholder file for the user to download and test\n","print(\"\\nIMPORTANT: Please download the 'Test Blob File.pdf' from the file browser on the left to test the application.\")\n","!wget -q https://storage.googleapis.com/generativeai-downloads/data/Test%20Blob%20File.pdf -O \"/content/Test Blob File.pdf\"\n","\n","print(\"\\n🚀 Launching Gradio App...\")\n","app.launch(debug=True, share=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C1IHCnpk_mMi"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"putVnkpF-3Qh"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9013,"status":"ok","timestamp":1759209373797,"user":{"displayName":"Dfe Shah","userId":"02290639415740118939"},"user_tz":-330},"id":"w1xARkqS-3UH","outputId":"6b0f50f2-4fdc-4579-d6e3-db4f7ad84974"},"outputs":[{"name":"stdout","output_type":"stream","text":["⏳ Installing specific, compatible library versions...\n","\u001b[31mERROR: Cannot install gradio==4.29.0 and gradio_client==0.16.0 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n","\u001b[0m✅ Installations complete.\n"]}],"source":["# ==============================================================================\n","# Step 1: Run this Controlled Installation Cell\n","# ==============================================================================\n","print(\"⏳ Installing specific, compatible library versions...\")\n","\n","# This command installs all required packages with pinned versions to ensure compatibility.\n","!pip install \\\n","    \"gradio==4.29.0\" \\\n","    \"gradio_client==0.16.0\" \\\n","    \"llama-index==0.10.34\" \\\n","    \"pypdf==4.2.0\" \\\n","    \"pymupdf==1.24.1\" \\\n","    \"numpy==1.26.4\" \\\n","    \"llama-cpp-python==0.2.73\" \\\n","    \"llama-index-llms-llama-cpp==0.1.3\" \\\n","    \"llama-index-embeddings-huggingface==0.2.0\" \\\n","    --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu122 -q\n","\n","print(\"✅ Installations complete.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"id":"GVIOvV_B-6r5"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/pypdf/_crypt_providers/_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from this module in 48.0.0.\n","  from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4\n","[nltk_data] Downloading package punkt_tab to\n","[nltk_data]     /usr/local/lib/python3.12/dist-\n","[nltk_data]     packages/llama_index/core/_static/nltk_cache...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]},{"name":"stdout","output_type":"stream","text":["⏳ Setting up...\n","⏳ Downloading Mistral 7B model...\n","--2025-09-30 05:17:17--  https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q4_K_M.gguf\n","Resolving huggingface.co (huggingface.co)... 13.35.202.34, 13.35.202.40, 13.35.202.121, ...\n","Connecting to huggingface.co (huggingface.co)|13.35.202.34|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/65778ac662d3ac1817cc9201/865f5e4682dddb29c2e20270b2471a7590c83a414bbf1d72cf4c08fdff2eeca4?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026X-Amz-Content-Sha256=UNSIGNED-PAYLOAD\u0026X-Amz-Credential=cas%2F20250930%2Fus-east-1%2Fs3%2Faws4_request\u0026X-Amz-Date=20250930T051240Z\u0026X-Amz-Expires=3600\u0026X-Amz-Signature=0d0053b458cb7a2ee48b4a58e700ccb2dacdf20255b49f66afd98ca3a5eaae31\u0026X-Amz-SignedHeaders=host\u0026X-Xet-Cas-Uid=public\u0026response-content-disposition=inline%3B+filename*%3DUTF-8%27%27mistral-7b-instruct-v0.2.Q4_K_M.gguf%3B+filename%3D%22mistral-7b-instruct-v0.2.Q4_K_M.gguf%22%3B\u0026x-id=GetObject\u0026Expires=1759212760\u0026Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1OTIxMjc2MH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NTc3OGFjNjYyZDNhYzE4MTdjYzkyMDEvODY1ZjVlNDY4MmRkZGIyOWMyZTIwMjcwYjI0NzFhNzU5MGM4M2E0MTRiYmYxZDcyY2Y0YzA4ZmRmZjJlZWNhNCoifV19\u0026Signature=JwSQYpEs%7EtquWWVlAW6lEHqxgvkOdfw4nViqm7cVgQayrciyB9Hr2w2mvTj%7Etsxw0YaPTZuK7J4BXjZk4noUiFwGPJylTwS2a59FvBMSELs6wmqymw-SQp8ulhe4GSgio3TjsifR1b24vkLErAEZVboZITpr8gVhJfkZth6sbbwf4o6KO47vRTCbP4EP8RzHYmXXNvU34ZLVoZbzFbgi%7EXyA%7E04szBidjZRr9ht9Cas6Vck9-xXoOUhzmx-MECaPxfi8AmCy4HzmgjXLUqk87wHX7V2YxhIeXfZT3E3rOwOyW8fVrWR7cCFV4AfLigWkYbG2LZsWWZ%7E5nC14nqDj-w__\u0026Key-Pair-Id=K2L8F4GPSG1IFC [following]\n","--2025-09-30 05:17:17--  https://cas-bridge.xethub.hf.co/xet-bridge-us/65778ac662d3ac1817cc9201/865f5e4682dddb29c2e20270b2471a7590c83a414bbf1d72cf4c08fdff2eeca4?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026X-Amz-Content-Sha256=UNSIGNED-PAYLOAD\u0026X-Amz-Credential=cas%2F20250930%2Fus-east-1%2Fs3%2Faws4_request\u0026X-Amz-Date=20250930T051240Z\u0026X-Amz-Expires=3600\u0026X-Amz-Signature=0d0053b458cb7a2ee48b4a58e700ccb2dacdf20255b49f66afd98ca3a5eaae31\u0026X-Amz-SignedHeaders=host\u0026X-Xet-Cas-Uid=public\u0026response-content-disposition=inline%3B+filename*%3DUTF-8%27%27mistral-7b-instruct-v0.2.Q4_K_M.gguf%3B+filename%3D%22mistral-7b-instruct-v0.2.Q4_K_M.gguf%22%3B\u0026x-id=GetObject\u0026Expires=1759212760\u0026Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1OTIxMjc2MH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NTc3OGFjNjYyZDNhYzE4MTdjYzkyMDEvODY1ZjVlNDY4MmRkZGIyOWMyZTIwMjcwYjI0NzFhNzU5MGM4M2E0MTRiYmYxZDcyY2Y0YzA4ZmRmZjJlZWNhNCoifV19\u0026Signature=JwSQYpEs%7EtquWWVlAW6lEHqxgvkOdfw4nViqm7cVgQayrciyB9Hr2w2mvTj%7Etsxw0YaPTZuK7J4BXjZk4noUiFwGPJylTwS2a59FvBMSELs6wmqymw-SQp8ulhe4GSgio3TjsifR1b24vkLErAEZVboZITpr8gVhJfkZth6sbbwf4o6KO47vRTCbP4EP8RzHYmXXNvU34ZLVoZbzFbgi%7EXyA%7E04szBidjZRr9ht9Cas6Vck9-xXoOUhzmx-MECaPxfi8AmCy4HzmgjXLUqk87wHX7V2YxhIeXfZT3E3rOwOyW8fVrWR7cCFV4AfLigWkYbG2LZsWWZ%7E5nC14nqDj-w__\u0026Key-Pair-Id=K2L8F4GPSG1IFC\n","Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 18.155.68.46, 18.155.68.125, 18.155.68.14, ...\n","Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|18.155.68.46|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4368439584 (4.1G)\n","Saving to: ‘/content/mistral-7b-instruct-v0.2.Q4_K_M.gguf’\n","\n","/content/mistral-7b 100%[===================\u003e]   4.07G  83.5MB/s    in 30s     \n","\n","2025-09-30 05:17:47 (140 MB/s) - ‘/content/mistral-7b-instruct-v0.2.Q4_K_M.gguf’ saved [4368439584/4368439584]\n","\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6b8b4c93308348378b43fd7070b524ee","version_major":2,"version_minor":0},"text/plain":["modules.json:   0%|          | 0.00/349 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"852fa68d637c4f9ab78ed10c387af5b3","version_major":2,"version_minor":0},"text/plain":["config_sentence_transformers.json:   0%|          | 0.00/124 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bee00e91d65c47008a662522dd71b068","version_major":2,"version_minor":0},"text/plain":["README.md: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8d01c9a0fcb248d5be9fa727bbac830a","version_major":2,"version_minor":0},"text/plain":["sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9381b72c41a94b2c93dc336c583777f2","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/743 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8636dbdd656649f592765ffda3b98421","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/133M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"994d933e872548a3b34726380ce789dc","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/366 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"79eda0d7b19b433f857f089e4e70ab5d","version_major":2,"version_minor":0},"text/plain":["vocab.txt: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d926ed258fb94fdd954e2643704b8293","version_major":2,"version_minor":0},"text/plain":["tokenizer.json: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f39c008e8d8b45f298ff330d000ebcf2","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/125 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"73bd5c5155e24056bba60288a478f189","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/190 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["✅ Models loaded.\n","\n","🚀 Launching Gradio App...\n","Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n","* Running on public URL: https://eefc4d929958737631.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"data":{"text/html":["\u003cdiv\u003e\u003ciframe src=\"https://eefc4d929958737631.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen\u003e\u003c/iframe\u003e\u003c/div\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["# ==============================================================================\n","# Step 3: Run the Full Application Code in a New Cell\n","# ==============================================================================\n","\n","# Imports and Model Loading\n","# ==============================================================================\n","import gradio as gr\n","import os\n","import json\n","import time\n","import fitz\n","from pypdf import PdfReader\n","from llama_index.core import Document, VectorStoreIndex, Settings\n","from llama_index.core.vector_stores import ExactMatchFilter, MetadataFilters\n","from llama_index.llms.llama_cpp import LlamaCPP\n","from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n","from typing import List, Dict\n","from PIL import Image\n","\n","print(\"⏳ Setting up...\")\n","model_path = \"/content/mistral-7b-instruct-v0.2.Q4_K_M.gguf\"\n","if not os.path.exists(model_path):\n","    print(\"⏳ Downloading Mistral 7B model...\")\n","    !wget https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q4_K_M.gguf -O {model_path}\n","\n","Settings.llm = LlamaCPP(\n","    model_path=model_path, temperature=0.1, max_new_tokens=512,\n","    context_window=3900, model_kwargs={\"n_gpu_layers\": 35}, verbose=False\n",")\n","Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n","print(\"✅ Models loaded.\")\n","\n","# Backend Pipeline Logic\n","# ==============================================================================\n","class DocumentIntelligencePipeline:\n","    def __init__(self):\n","        self.index = None; self.file_name = \"\"\n","        self.doc_types_in_file = []\n","\n","    def process_and_index_document(self, pdf_path: str):\n","        self.file_name = os.path.basename(pdf_path)\n","        reader = PdfReader(pdf_path)\n","        pages = [{\"text\": page.extract_text()} for page in reader.pages]\n","        if not pages: raise ValueError(\"Could not extract pages.\")\n","\n","        documents_to_index = []\n","        doc_types_found = set()\n","        for i, page in enumerate(pages):\n","            doc_type = \"Document\"\n","            doc_types_found.add(doc_type)\n","            metadata = {\"page_number\": i + 1, \"doc_type\": doc_type}\n","            doc = Document(text=page['text'], metadata=metadata)\n","            documents_to_index.append(doc)\n","\n","        self.index = VectorStoreIndex.from_documents(documents_to_index)\n","        self.doc_types_in_file = list(doc_types_found)\n","        stats = {\"File\": self.file_name, \"Pages\": len(pages)}\n","        return stats\n","\n","    def query(self, user_query: str, top_k: int):\n","        if not self.index: return {\"answer\": \"Please process a document first.\", \"sources\": \"\"}\n","        retriever = self.index.as_retriever(similarity_top_k=int(top_k))\n","        nodes = retriever.retrieve(user_query)\n","        context = \"\\n\\n\".join([n.get_text() for n in nodes])\n","        prompt = f\"[INST] Use context to answer. Question: {user_query} [/INST]\\nContext:\\n{context}\"\n","        response = Settings.llm.complete(prompt)\n","        sources = \"--- SOURCES ---\\n\" + \"\\n\".join([f\"**Source {i+1} (Page: {n.metadata['page_number']})**:\\n```{n.get_text()[:200].strip()}...```\" for i, n in enumerate(nodes)])\n","        return {\"answer\": response.text.strip(), \"sources\": sources}\n","\n","pipeline = DocumentIntelligencePipeline()\n","\n","# Gradio UI and Handlers\n","# ==============================================================================\n","def process_pdf_and_update_ui(file, progress=gr.Progress()):\n","    if file is None: return None, \"⚠️ Please upload a PDF.\", [], gr.update(interactive=False)\n","\n","    doc = fitz.open(file.name)\n","    pix = doc[0].get_pixmap(dpi=150)\n","    preview_image = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n","    doc.close()\n","\n","    progress(0.1, desc=\"📄 Indexing PDF...\")\n","    stats = pipeline.process_and_index_document(file.name)\n","    info_text = f\"✅ **Processed:**\\n- **File:** {stats['File']}\\n- **Pages:** {stats['Pages']}\"\n","    progress(1.0, desc=\"✅ Ready.\")\n","    return preview_image, info_text, [], gr.update(interactive=True)\n","\n","def chat_handler(message, history, top_k):\n","    if not pipeline.index:\n","        history.append({\"role\": \"user\", \"content\": message})\n","        history.append({\"role\": \"assistant\", \"content\": \"Please process a document first.\"})\n","        yield history, \"\", \"\"\n","        return\n","    history.append({\"role\": \"user\", \"content\": message})\n","    history.append({\"role\": \"assistant\", \"content\": \"Thinking...\"})\n","    yield history, \"\", \"\"\n","    result = pipeline.query(message, top_k)\n","    history[-1]['content'] = result[\"answer\"]\n","    yield history, result[\"sources\"], \"\"\n","\n","with gr.Blocks(theme=gr.themes.Soft(primary_hue=\"sky\"), title=\"Document Q\u0026A\") as app:\n","    gr.Markdown(\"# 🚀 Document Q\u0026A System\")\n","    with gr.Row(equal_height=False):\n","        with gr.Column(scale=4, min_width=400):\n","            file_uploader = gr.File(label=\"📄 Upload PDF File\", file_types=[\".pdf\"])\n","            process_btn = gr.Button(\"⚙️ Process Document\", variant=\"primary\")\n","            pdf_preview = gr.Image(label=\"PDF Preview (First Page)\", height=650)\n","        with gr.Column(scale=2, min_width=300):\n","            info_output = gr.Markdown(value=\"Please upload a PDF file to begin.\")\n","            chunks_to_retrieve = gr.Slider(minimum=1, maximum=10, value=3, step=1, label=\"📊 Chunks to Retrieve\")\n","        with gr.Column(scale=4, min_width=400):\n","            chatbot = gr.Chatbot(label=\"Chat\", height=500, type=\"messages\")\n","            source_display = gr.Markdown(label=\"Sources Used for Answer\")\n","            msg_box = gr.Textbox(label=\"Your Question\", placeholder=\"Ask a question...\", interactive=False, container=False)\n","    process_btn.click(process_pdf_and_update_ui, inputs=[file_uploader], outputs=[pdf_preview, info_output, chatbot, msg_box])\n","    msg_box.submit(chat_handler, inputs=[msg_box, chatbot, chunks_to_retrieve], outputs=[chatbot, source_display, msg_box])\n","\n","# Launch the App\n","# ==============================================================================\n","test_file_path = \"/content/Test Blob File.pdf\"\n","if not os.path.exists(test_file_path):\n","    !wget -q https://storage.googleapis.com/generativeai-downloads/data/Test%20Blob%20File.pdf -O \"/content/Test Blob File.pdf\"\n","print(\"\\n🚀 Launching Gradio App...\")\n","app.launch(debug=True, share=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6W9sV4OBDTHd"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMr1lZWy+9B8zSpDDpHvlAI","gpuType":"T4","mount_file_id":"1t6oXOu8RltHkC38kc6HYFTZmFKFu1e_G","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"028bf88671204b28af21aacea25ea4d7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d06dc0e802d7441183e786679fe4d818","placeholder":"​","style":"IPY_MODEL_4acd34c27f364c63ad359517670fa347","value":"config.json: 100%"}},"1146a2f7e35542d4b651571f08273776":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d2aa26f0d6042ddb4984e7d88a6bb24":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f9415fae23648d39988e089ecaf38ea":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"204423d926334b1483182ecc5dd32f66":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ffb54751f65149f0b7788d40057f0368","placeholder":"​","style":"IPY_MODEL_206befaffbf340b096cb6d2136c6466d","value":" 125/125 [00:00\u0026lt;00:00, 15.8kB/s]"}},"206befaffbf340b096cb6d2136c6466d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"22a27dc6ce5041e8bbb019cfccca28a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_69b1aee2fb694523b54c4b9e0c747976","placeholder":"​","style":"IPY_MODEL_bbfcb2ae146143b7a878ff5beb8e6d2d","value":" 711k/? [00:00\u0026lt;00:00, 44.7MB/s]"}},"28334fc35c93410ca3c2d9b4066bb679":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_83fbcfed787440fa869c9e1e328849c7","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4e96463225f94725b05c19058caa0ed8","value":52}},"2cbecb23ea5346558a220723e6e84b75":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0b9aa6aebbc4c84a06f4589a52d98f5","placeholder":"​","style":"IPY_MODEL_bd85f4727ed34b77ac3228feeddfda4c","value":" 52.0/52.0 [00:00\u0026lt;00:00, 6.71kB/s]"}},"2e50f7c7e25c44a48fbc187fc127c2da":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2fd20a4561aa4593abaa49a3e1ea0787":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ffc7165ce5340589eddcdb4d7e79ac8","placeholder":"​","style":"IPY_MODEL_4fc0cadac9fb4bd5ba396ae581a2be6b","value":" 94.8k/? [00:00\u0026lt;00:00, 8.84MB/s]"}},"307579e7e2c34036922ef033dd0173ca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3163e6c6d6114b189d98e4e7257cf2b7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_80a9669692ee48baaf2bc2f778ba9219","placeholder":"​","style":"IPY_MODEL_fa5df09b4c34473aa8fb4f8d2d874ba3","value":" 124/124 [00:00\u0026lt;00:00, 14.1kB/s]"}},"3516417400a1426f8b75c981d5f78de8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_db93e67412094fd4b1bb0717065cc108","placeholder":"​","style":"IPY_MODEL_57079c125111472793fc4ba72760a6d3","value":"special_tokens_map.json: 100%"}},"37ca3224e65d4ea7a2adcc86e0b9acb2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3b701f341af54338abb36f37b120c561":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3fd147457f564e668d50c54ba12ab6c8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5932f3a309b45d594ddabcb3d18c50c","placeholder":"​","style":"IPY_MODEL_c05c6719650f4ed99dd671015c8c7e90","value":" 349/349 [00:00\u0026lt;00:00, 39.7kB/s]"}},"443081a3a2b74e73bc938e98a664fb64":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"481b2a1cd7ee482689ea5ef63601ff74":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4937888d6e5943489ea872d4e51dc0bb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4acd34c27f364c63ad359517670fa347":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e34912ebd1d4defb057a79afc193dea":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e96463225f94725b05c19058caa0ed8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4fc0cadac9fb4bd5ba396ae581a2be6b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"57079c125111472793fc4ba72760a6d3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5f92f64972414fb89a83e53447374597":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"621481c7554f4bd5b5da18ababcc292f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_da5440d20e7b4a5fb13fb5a2e2317b3e","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_df40596f309e44f7a8b338d2414c5c5a","value":1}},"671252e74c914a7c93b477aa847c3f6a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d5e233299da4c30bd1fb78a91e038ad","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_de00d16442ef4939b097c115edd476ad","value":1}},"68584f6608254ef199ad70e01dc25265":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68940496c68248e09f3363f939cdddd2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e34912ebd1d4defb057a79afc193dea","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_307579e7e2c34036922ef033dd0173ca","value":124}},"692b57fc12bf4ffc99985e6a7cb29c34":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f92f64972414fb89a83e53447374597","placeholder":"​","style":"IPY_MODEL_1d2aa26f0d6042ddb4984e7d88a6bb24","value":"sentence_bert_config.json: 100%"}},"69b1aee2fb694523b54c4b9e0c747976":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a0263930ed94ea097ef605d1bff4ccd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e851beffb8a6449b8a1547de31997e48","max":743,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b8f8a2a357a6475995c0b3eeeb9d785b","value":743}},"6b8b4c93308348378b43fd7070b524ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fb4159281adf4a76934f761f6b3cc7e0","IPY_MODEL_c6f60cf67f07485b884bf14118014e08","IPY_MODEL_3fd147457f564e668d50c54ba12ab6c8"],"layout":"IPY_MODEL_90fc0c540de048e1baf9bc2b4cfca50f"}},"73bd5c5155e24056bba60288a478f189":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_028bf88671204b28af21aacea25ea4d7","IPY_MODEL_df3d8177b3a148f59a92cc490b16b263","IPY_MODEL_94242aaf611d4d7ea8aa1a80e369b45e"],"layout":"IPY_MODEL_e2c2f3e09ee348ce8db3af4e52ea6a5f"}},"747de40fc244436ab06cde213790811b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79eda0d7b19b433f857f089e4e70ab5d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f12f90d3a06f401f8c1f021c2d0a93b8","IPY_MODEL_621481c7554f4bd5b5da18ababcc292f","IPY_MODEL_c7fceae14ce74c4abafb17537aee6c60"],"layout":"IPY_MODEL_b442851823da414e9a64f6d0ecc1c472"}},"7adc22ce2162448ab0257627172b6982":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80a9669692ee48baaf2bc2f778ba9219":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8110ed6482bf42caa4d57f15dd9bebd1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9fc374fb99604831b4894e506c28f318","max":366,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f2a1cb930eb84d50a26634cbd7378269","value":366}},"828082c457b741dbb30c0afe5359bea1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83fbcfed787440fa869c9e1e328849c7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"852fa68d637c4f9ab78ed10c387af5b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_973bd7e66c0046e6b48893138c2f3cb7","IPY_MODEL_68940496c68248e09f3363f939cdddd2","IPY_MODEL_3163e6c6d6114b189d98e4e7257cf2b7"],"layout":"IPY_MODEL_ae6f97f5ed9944c08a505328b7c88d5b"}},"862a96011f74498ca21c1f6661bab3d6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8636dbdd656649f592765ffda3b98421":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9e99fea1fea64d95aec143092bcb065d","IPY_MODEL_c544e50dd6d74757bb956bd109a6dcb0","IPY_MODEL_e63cbf1b4b6449318c5ca5dbd47e6d30"],"layout":"IPY_MODEL_a76362a848e24c118e3d37fca2ad13a0"}},"8a3aacaf613245cb863c707b1c538c20":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c75a08e1ecd4a42a42d990839e2a3a2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b701f341af54338abb36f37b120c561","placeholder":"​","style":"IPY_MODEL_bd323efb5f794c3cb313b55da56376e9","value":"config.json: 100%"}},"8d01c9a0fcb248d5be9fa727bbac830a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_692b57fc12bf4ffc99985e6a7cb29c34","IPY_MODEL_28334fc35c93410ca3c2d9b4066bb679","IPY_MODEL_2cbecb23ea5346558a220723e6e84b75"],"layout":"IPY_MODEL_e7194e6e9c4d4f21b07ac493e244e212"}},"8d5e233299da4c30bd1fb78a91e038ad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"8e4660bad4264886a8b091b3d81fb938":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8ffc7165ce5340589eddcdb4d7e79ac8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90fc0c540de048e1baf9bc2b4cfca50f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"920a1d6d21584499bcbe991c2582d25a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"933caec4148b474bb7687ca14b4fda50":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9381b72c41a94b2c93dc336c583777f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8c75a08e1ecd4a42a42d990839e2a3a2","IPY_MODEL_6a0263930ed94ea097ef605d1bff4ccd","IPY_MODEL_be408827178f40e88544fc85eccd2a5e"],"layout":"IPY_MODEL_ad69398746564a649e3fd8551f1b9939"}},"94242aaf611d4d7ea8aa1a80e369b45e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9e479f1df97436aa9360abe66f2afc9","placeholder":"​","style":"IPY_MODEL_862a96011f74498ca21c1f6661bab3d6","value":" 190/190 [00:00\u0026lt;00:00, 24.2kB/s]"}},"973bd7e66c0046e6b48893138c2f3cb7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_af1d14c0ab904e22a12cafe53373a95b","placeholder":"​","style":"IPY_MODEL_8a3aacaf613245cb863c707b1c538c20","value":"config_sentence_transformers.json: 100%"}},"9884149657f64067a6a612cc360d568e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"994d933e872548a3b34726380ce789dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bd93f8117947459ea0154a0d6f434ebc","IPY_MODEL_8110ed6482bf42caa4d57f15dd9bebd1","IPY_MODEL_c8459e5e43d6467289f1700ffd7b16a7"],"layout":"IPY_MODEL_9e54fe642d2d41f2bfc67a7ed61e19c4"}},"9e1e47e001f747bfaa6919ad54f42d35":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e54fe642d2d41f2bfc67a7ed61e19c4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e87b0ae951d415780895aa7ce93b0b7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e99fea1fea64d95aec143092bcb065d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1146a2f7e35542d4b651571f08273776","placeholder":"​","style":"IPY_MODEL_37ca3224e65d4ea7a2adcc86e0b9acb2","value":"model.safetensors: 100%"}},"9f7636fd1d6c44cb9024b93844a95533":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fc374fb99604831b4894e506c28f318":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fc82a85f38f4718b80bf8ce79bd3079":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d14928cf9f2f452f9766a85a0f24fec4","max":125,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2e50f7c7e25c44a48fbc187fc127c2da","value":125}},"a0b9aa6aebbc4c84a06f4589a52d98f5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a41c00613bb648dbb872af27facd17ef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f7636fd1d6c44cb9024b93844a95533","placeholder":"​","style":"IPY_MODEL_920a1d6d21584499bcbe991c2582d25a","value":"README.md: "}},"a76362a848e24c118e3d37fca2ad13a0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad1c3e94cf484ceb9f765d00db3b213c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb58d11a01ad46bcb01326d5f744a9ea","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fe4377523fd243b2adb6b61ea3441fdc","value":1}},"ad69398746564a649e3fd8551f1b9939":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae6f97f5ed9944c08a505328b7c88d5b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af1d14c0ab904e22a12cafe53373a95b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1054188e01545b3a9890f227207abd1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b442851823da414e9a64f6d0ecc1c472":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8f8a2a357a6475995c0b3eeeb9d785b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bae695235dbd40f091b738a262ebf4be":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bbfcb2ae146143b7a878ff5beb8e6d2d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bccbc4f6bb37493687d8cdc8778afa1f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd323efb5f794c3cb313b55da56376e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd85f4727ed34b77ac3228feeddfda4c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd93f8117947459ea0154a0d6f434ebc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cdfe35d2ee3945ae83b8a97316a0fcc6","placeholder":"​","style":"IPY_MODEL_9884149657f64067a6a612cc360d568e","value":"tokenizer_config.json: 100%"}},"be408827178f40e88544fc85eccd2a5e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4937888d6e5943489ea872d4e51dc0bb","placeholder":"​","style":"IPY_MODEL_f113e856711d4ea2b04cf44de72191f6","value":" 743/743 [00:00\u0026lt;00:00, 67.5kB/s]"}},"bee00e91d65c47008a662522dd71b068":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a41c00613bb648dbb872af27facd17ef","IPY_MODEL_671252e74c914a7c93b477aa847c3f6a","IPY_MODEL_2fd20a4561aa4593abaa49a3e1ea0787"],"layout":"IPY_MODEL_9e87b0ae951d415780895aa7ce93b0b7"}},"c05c6719650f4ed99dd671015c8c7e90":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1e379cd099b47d9adb20f6bade5072d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c2787014b2014465bfd4345bc0189fa9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4233410458d42b3b073969d353c0ade":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c544e50dd6d74757bb956bd109a6dcb0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bae695235dbd40f091b738a262ebf4be","max":133466304,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c1e379cd099b47d9adb20f6bade5072d","value":133466304}},"c6f60cf67f07485b884bf14118014e08":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f9415fae23648d39988e089ecaf38ea","max":349,"min":0,"orientation":"horizontal","style":"IPY_MODEL_443081a3a2b74e73bc938e98a664fb64","value":349}},"c7fceae14ce74c4abafb17537aee6c60":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e1e47e001f747bfaa6919ad54f42d35","placeholder":"​","style":"IPY_MODEL_c4233410458d42b3b073969d353c0ade","value":" 232k/? [00:00\u0026lt;00:00, 14.4MB/s]"}},"c8459e5e43d6467289f1700ffd7b16a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7adc22ce2162448ab0257627172b6982","placeholder":"​","style":"IPY_MODEL_8e4660bad4264886a8b091b3d81fb938","value":" 366/366 [00:00\u0026lt;00:00, 38.3kB/s]"}},"cb58d11a01ad46bcb01326d5f744a9ea":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"cd16261abed040ebb55e64da78fe1dea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cdfe35d2ee3945ae83b8a97316a0fcc6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d06dc0e802d7441183e786679fe4d818":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d14928cf9f2f452f9766a85a0f24fec4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d926ed258fb94fdd954e2643704b8293":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fa49175a94f0452a90a02dc038aa2138","IPY_MODEL_ad1c3e94cf484ceb9f765d00db3b213c","IPY_MODEL_22a27dc6ce5041e8bbb019cfccca28a1"],"layout":"IPY_MODEL_747de40fc244436ab06cde213790811b"}},"da5440d20e7b4a5fb13fb5a2e2317b3e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"db93e67412094fd4b1bb0717065cc108":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de00d16442ef4939b097c115edd476ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"df3d8177b3a148f59a92cc490b16b263":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_828082c457b741dbb30c0afe5359bea1","max":190,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cd16261abed040ebb55e64da78fe1dea","value":190}},"df40596f309e44f7a8b338d2414c5c5a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e2c2f3e09ee348ce8db3af4e52ea6a5f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e63cbf1b4b6449318c5ca5dbd47e6d30":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_481b2a1cd7ee482689ea5ef63601ff74","placeholder":"​","style":"IPY_MODEL_bccbc4f6bb37493687d8cdc8778afa1f","value":" 133M/133M [00:02\u0026lt;00:00, 84.1MB/s]"}},"e7194e6e9c4d4f21b07ac493e244e212":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e851beffb8a6449b8a1547de31997e48":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9e479f1df97436aa9360abe66f2afc9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed78dd3201ca4c1095a3bd257aaac63e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f113e856711d4ea2b04cf44de72191f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f12f90d3a06f401f8c1f021c2d0a93b8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed78dd3201ca4c1095a3bd257aaac63e","placeholder":"​","style":"IPY_MODEL_f40e6355924b4ad78f5a719b7665305a","value":"vocab.txt: "}},"f2a1cb930eb84d50a26634cbd7378269":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f39c008e8d8b45f298ff330d000ebcf2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3516417400a1426f8b75c981d5f78de8","IPY_MODEL_9fc82a85f38f4718b80bf8ce79bd3079","IPY_MODEL_204423d926334b1483182ecc5dd32f66"],"layout":"IPY_MODEL_b1054188e01545b3a9890f227207abd1"}},"f40e6355924b4ad78f5a719b7665305a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f5932f3a309b45d594ddabcb3d18c50c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f63b68c958cb4d0a8c30a14e09f72c4f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fa49175a94f0452a90a02dc038aa2138":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_933caec4148b474bb7687ca14b4fda50","placeholder":"​","style":"IPY_MODEL_f63b68c958cb4d0a8c30a14e09f72c4f","value":"tokenizer.json: "}},"fa5df09b4c34473aa8fb4f8d2d874ba3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb4159281adf4a76934f761f6b3cc7e0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2787014b2014465bfd4345bc0189fa9","placeholder":"​","style":"IPY_MODEL_68584f6608254ef199ad70e01dc25265","value":"modules.json: 100%"}},"fe4377523fd243b2adb6b61ea3441fdc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ffb54751f65149f0b7788d40057f0368":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}